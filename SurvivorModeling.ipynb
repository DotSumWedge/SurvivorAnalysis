{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6dfc62e",
   "metadata": {},
   "source": [
    "## Survivor Data Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee31e08",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "639ee194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the path to the survivorData directory\n",
    "data_dir = os.path.join(current_dir, '..', 'survivorData')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c4d6aa8",
   "metadata": {},
   "source": [
    "### Read in csv files as Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e239ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file names\n",
    "csv_files = [\n",
    "    'advantage_movement.csv',\n",
    "    'boot_mapping.csv',\n",
    "    'castaways.csv',\n",
    "    'castaway_details.csv',\n",
    "    'challenge_description.csv',\n",
    "    'challenge_results.csv',\n",
    "    'confessionals.csv',\n",
    "    'jury_votes.csv',\n",
    "    'screen_time.csv',\n",
    "    'season_palettes.csv',\n",
    "    'season_summary.csv',\n",
    "    'survivor_auction.csv',\n",
    "    'tribe_colours.csv',\n",
    "    'tribe_mapping.csv',\n",
    "    'viewers.csv',\n",
    "    'vote_history.csv'\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each CSV file and read its data into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    # Specify the relative path to the CSV file\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "    \n",
    "    # Read the data from the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[csv_file] = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c5e475b",
   "metadata": {},
   "source": [
    "### Clean up the data and feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0c4624e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tribe_status column to category type\n",
    "dataframes['tribe_colours.csv']['tribe_status'] = dataframes['tribe_colours.csv']['tribe_status'].astype('category')\n",
    "\n",
    "# Convert result to a categorical variable\n",
    "dataframes['castaways.csv']['result'] = pd.Categorical(dataframes['castaways.csv']['result'])\n",
    "dataframes['castaways.csv']['result'] = dataframes['castaways.csv']['result'].cat.codes\n",
    "\n",
    "# Merge challenge_results and castaway_details dataframes on castaway_id\n",
    "castawayAll = pd.merge(dataframes['castaways.csv'], dataframes['castaway_details.csv'], on='castaway_id', how =\"left\")\n",
    "\n",
    "castawayAll['genderNumber'] = np.where(castawayAll['gender'] == 'Male', 1,\n",
    "                                     np.where(castawayAll['gender'] == 'Female', 2,\n",
    "                                              np.where(castawayAll['gender'] == 'Non-binary', 3, 0)))\n",
    "castawayAll['won'] = np.where(castawayAll['result'] == 'Sole Survivor', 1, 0)\n",
    "\n",
    "castawayAll = castawayAll.dropna(subset=['age'])\n",
    "\n",
    "# Drop rows where 'season' is equal to 44\n",
    "castawayAll = castawayAll[castawayAll['season'] != 44]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a0a73ac",
   "metadata": {},
   "source": [
    "## Predicting Color Values in the survivor dataset: A Comparative Analysis of SVM and Logistic Regression Models\n",
    "\n",
    "### Introduction:\n",
    "In this overview, we will delve into the rationale behind predicting color values in a dataset and explore the unique situation it presents when it comes to quantifying results. Specifically, we will compare the performance of Support Vector Machine (SVM) and Logistic Regression models in predicting color values and evaluate the effectiveness of various metrics such as average accuracy, Hamming distance, and Euclidean distance.\n",
    "\n",
    "### Predicting Color Values in a Dataset:\n",
    "Color is an essential aspect of visual data analysis and has a wide range of applications, including image processing, computer vision, and data visualization. By predicting color values in a dataset, we can gain insights into patterns, trends, and relationships that are not immediately apparent to the human eye. This predictive modeling approach allows us to develope skills to uncover hidden information and make data-driven decisions.\n",
    "\n",
    "### Comparison of SVM and Logistic Regression Models:\n",
    "To determine the best approach for predicting color values, we have chosen to compare the performance of two popular machine learning algorithms: Support Vector Machine (SVM) and Logistic Regression. Both models are widely used in classification tasks and have demonstrated success in various domains.\n",
    "\n",
    "1. Support Vector Machine (SVM):\n",
    "SVM is a powerful algorithm that aims to find an optimal hyperplane in a high-dimensional feature space. It separates data points into distinct classes by maximizing the margin between them. SVM is known for its ability to handle complex datasets and nonlinear relationships effectively. Its versatility and robustness make it a suitable candidate for predicting color values in a dataset.\n",
    "\n",
    "2. Logistic Regression:\n",
    "Logistic Regression is a probabilistic machine learning algorithm used for binary classification tasks. It models the relationship between the input features and the probability of a particular outcome. Logistic Regression is known for its simplicity, interpretability, and efficiency. While it may not capture complex nonlinear relationships as effectively as SVM, it can still yield accurate predictions in certain scenarios.\n",
    "\n",
    "### Quantifying Results:\n",
    "To evaluate the performance of our SVM and Logistic Regression models in predicting color values, we will utilize several metrics that address different aspects of model performance:\n",
    "\n",
    "1. Average Accuracy:\n",
    "Average accuracy measures the percentage of correctly classified instances across all classes.\n",
    "\n",
    "2. Hamming Distance:\n",
    "Hamming distance quantifies the dissimilarity between two color values by measuring the number of positions at which they differ. Since color values can be represented as vectors in a multi-dimensional space, Hamming distance provides a useful metric for evaluating the similarity or dissimilarity of predicted colors.\n",
    "\n",
    "3. Euclidean Distance:\n",
    "Euclidean distance measures the straight-line distance between two points in a multi-dimensional space. In the context of color values, Euclidean distance allows us to determine the proximity of predicted colors to the ground truth. \n",
    "\n",
    "### Conclusion:\n",
    "Predicting color values in a dataset presents a unique situation due to its visual and perceptual nature. By comparing the performance of SVM and Logistic Regression models, we can gain insights into the effectiveness of these algorithms in accurately predicting color values. Furthermore, by utilizing metrics such as average accuracy, Hamming distance, and Euclidean distance, we can comprehensively evaluate the performance of the models and make informed decisions regarding their suitability for color prediction tasks.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3d4b4e",
   "metadata": {},
   "source": [
    "## Color prediction with SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3fa1c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15217391304347827\n",
      "Average Hamming Distance for Incorrect Predictions: 4.565217391304348\n",
      "Average Euclidean Distance for All Predictions: 226.10113273427547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:202: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  return array[key] if axis == 0 else array[:, key]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training\n",
    "X = dataframes['tribe_colours.csv']['tribe_status'].values.reshape(-1, 1)\n",
    "y = dataframes['tribe_colours.csv']['tribe_colour']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "\n",
    "# Calculate Hamming distance for all predictions\n",
    "hamming_distances = []\n",
    "\n",
    "for idx in range(len(y_pred)):\n",
    "    hamming_dist = sum(el1 != el2 for el1, el2 in zip(y_pred[idx], y_test.iloc[idx]))\n",
    "    hamming_distances.append(hamming_dist)\n",
    "\n",
    "# Calculate average Hamming distance for incorrect predictions\n",
    "avg_hamming_distance_svm = np.mean(hamming_distances)\n",
    "\n",
    "# The Hamming distance measures the dissimilarity between two strings of equal length. In the context of hex color values, \n",
    "# each character represents a component of the color (e.g., red, green, and blue), and the Hamming distance calculates \n",
    "# the number of positions at which the predicted and actual color values differ.\n",
    "\n",
    "# Since hex color values consist of six characters (e.g., #RRGGBB), the Hamming distance for hex color values can range from 0 to 6.\n",
    "\n",
    "# Print average Hamming distance for incorrect predictions\n",
    "print(\"Average Hamming Distance for Incorrect Predictions:\", avg_hamming_distance_svm)\n",
    "\n",
    "# Calculate Euclidean distance for color similarity\n",
    "euclidean_distances = []\n",
    "for idx in range(len(y_pred)):\n",
    "    predicted_color = y_pred[idx][1:]  # Remove the \"#\" character from the predicted color\n",
    "    actual_color = y_test.iloc[idx][1:]  # Remove the \"#\" character from the actual color\n",
    "    \n",
    "    # Convert hex color values to RGB tuples\n",
    "    predicted_rgb = tuple(int(predicted_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    actual_rgb = tuple(int(actual_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    \n",
    "    # Calculate Euclidean distance between RGB tuples\n",
    "    distance = math.sqrt(sum((p - a) ** 2 for p, a in zip(predicted_rgb, actual_rgb)))\n",
    "    euclidean_distances.append(distance)\n",
    "\n",
    "# Calculate average Euclidean distance for all predictions\n",
    "avg_euclidean_distance_svm = np.mean(euclidean_distances)\n",
    "\n",
    "# The Euclidean distance measures the spatial or geometric distance between two colors in the RGB color space.\n",
    "# In the RGB color space, each color is represented by three components: red (R), green (G), and blue (B). \n",
    "# The Euclidean distance calculates the straight-line distance between two colors in this three-dimensional space.\n",
    "\n",
    "# Print average Euclidean distance for all predictions\n",
    "print(\"Average Euclidean Distance for All Predictions:\", avg_euclidean_distance_svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59301fe6",
   "metadata": {},
   "source": [
    "## Color prediction with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "15e1402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08695652173913043\n",
      "Average Hamming Distance for Incorrect Predictions: 4.978260869565218\n",
      "Average Euclidean Distance for All Predictions: 241.9641118577173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_logistic_regression = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_logistic_regression)\n",
    "\n",
    "# Calculate Hamming distance for all predictions\n",
    "hamming_distances = []\n",
    "\n",
    "for idx in range(len(y_pred)):\n",
    "    hamming_dist = sum(el1 != el2 for el1, el2 in zip(y_pred[idx], y_test.iloc[idx]))\n",
    "    hamming_distances.append(hamming_dist)\n",
    "\n",
    "# Calculate average Hamming distance for incorrect predictions\n",
    "avg_hamming_distance_logistic_regression = np.mean(hamming_distances)\n",
    "\n",
    "# The Hamming distance measures the dissimilarity between two strings of equal length. In the context of hex color values, \n",
    "# each character represents a component of the color (e.g., red, green, and blue), and the Hamming distance calculates \n",
    "# the number of positions at which the predicted and actual color values differ.\n",
    "\n",
    "# Since hex color values consist of six characters (e.g., #RRGGBB), the Hamming distance for hex color values can range from 0 to 6.\n",
    "\n",
    "# Print average Hamming distance for incorrect predictions\n",
    "print(\"Average Hamming Distance for Incorrect Predictions:\", avg_hamming_distance_logistic_regression)\n",
    "\n",
    "# Calculate Euclidean distance for color similarity\n",
    "euclidean_distances = []\n",
    "for idx in range(len(y_pred)):\n",
    "    predicted_color = y_pred[idx][1:]  # Remove the \"#\" character from the predicted color\n",
    "    actual_color = y_test.iloc[idx][1:]  # Remove the \"#\" character from the actual color\n",
    "    \n",
    "    # Convert hex color values to RGB tuples\n",
    "    predicted_rgb = tuple(int(predicted_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    actual_rgb = tuple(int(actual_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    \n",
    "    # Calculate Euclidean distance between RGB tuples\n",
    "    distance = math.sqrt(sum((p - a) ** 2 for p, a in zip(predicted_rgb, actual_rgb)))\n",
    "    euclidean_distances.append(distance)\n",
    "\n",
    "# Calculate average Euclidean distance for all predictions\n",
    "avg_euclidean_distance_logistic_regression = np.mean(euclidean_distances)\n",
    "\n",
    "# The Euclidean distance measures the spatial or geometric distance between two colors in the RGB color space.\n",
    "# In the RGB color space, each color is represented by three components: red (R), green (G), and blue (B). \n",
    "# The Euclidean distance calculates the straight-line distance between two colors in this three-dimensional space.\n",
    "\n",
    "# Print average Euclidean distance for all predictions\n",
    "print(\"Average Euclidean Distance for All Predictions:\", avg_euclidean_distance_logistic_regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "988ba08a",
   "metadata": {},
   "source": [
    "## Color prediction model comparision\n",
    "\n",
    "Upon examining the graph plotted on a logarithmic scale, which enhances the visual representation of metric differences, a notable observation arises: the accuracy of the SVM model surpasses that of the Logistic Regression model by a significant margin. However, when considering the average Hamming distance and average Euclidean distance metrics, the difference between the two models is negligible.\n",
    "\n",
    "This log scale representation allows for a clearer visualization of the relative differences between the metrics. It accentuates the disparity in accuracy between SVM and Logistic Regression, emphasizing the stronger performance of SVM in terms of overall correct predictions. At the same time, the log scale helps highlight the close proximity of the two models in terms of the average Hamming distance and average Euclidean distance, indicating similar abilities to capture the patterns and relationships within the data.\n",
    "\n",
    "Therefore, taking into account the log scale representation, the graph reaffirms that SVM excels in accuracy compared to Logistic Regression, while both models demonstrate comparable results in terms of capturing the similarity between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c4216337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbdklEQVR4nO3dd1QU5/s28Guld0GkCqhYwIgF7EYBO5bYuwiCGhVjIV+NHTWWxMSSGOwR1NhLjFEUsRsxEVGMEUSNBQsEISqiQSnP+4cv83NlaQouONfnnD3JzDwzc884O3sxVSGEECAiIiKSoQrqLoCIiIhIXRiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GITKuT///BPDhg1DtWrVoKurC0NDQ7i6umLRokX4999/1V1eqfP19UXVqlXVXcY7u3jxItzd3WFiYgKFQoFly5bl21ahUEChUMDX11fl8Llz50ptbt++XexaIiMjMXv2bDx+/LhY41WtWjXfmt6nuLg4eHt7o3r16tDV1YW5uTlcXV0xduxYpKWlITMzE5aWlmjWrFm+08jJyYG9vT3q1asHADhx4oS0TkNDQ1WO06ZNGygUijKxPXp4eKBu3brvdZ63b98ucP3kZ8uWLflu7wqFArNnz37n2oBX22fuv6FCoYCBgQFcXV3xww8/QE4vWCjJdfrBEFRurVmzRmhqaoqPPvpIBAcHi+PHj4vDhw+LBQsWiGrVqokePXqou8RSd+PGDXHhwgV1l/HOGjRoIGrWrCnCwsLE2bNnRWJiYr5tAQgjIyOhr68v0tLSlIbl5OSIatWqCWNjYwFA3Lp1q9i1fPPNN2817oULF8SNGzeKPb+SdOHCBaGnpydcXV1FSEiIOH78uNi5c6eYMWOGqFGjhrRMn3/+uQAgrly5onI64eHhAoBYtmyZEEKI48ePS+v9448/ztP+5s2bQqFQCGNjY+Hg4FBai1dk7u7u4qOPPnqv88zIyBBnz54VycnJxRqvS5cu+a6zs2fPirt375ZAdUI4ODiIli1birNnz4qzZ8+K3bt3i5YtWwoAYv78+SUyj/KgJNfph4JBqJyKjIwUGhoaolOnTiIjIyPP8BcvXohffvlFDZW9H8+ePVN3CSVKU1NTjB49ukhtAYghQ4YIPT09sWbNGqVhR44cEQDEiBEj3lsQev78ebHnUVqGDh0qDAwM8gTEXDk5OUIIIWJjYwUA8fnnn6ts179/f6GtrS1SUlKEEP8XhIYPHy4AiGvXrim1nzFjhqhSpYrw8vKSbRB6WwUFoZLk4OAgunTpotTvyZMnwsTERNjb25f6/N/0/PlzaXsk9eKpsXJqwYIFUCgUWLNmDXR0dPIM19bWxieffCJ15+TkYNGiRXBycoKOjg4sLCwwdOhQ3Lt3T2m83EPqZ8+eRYsWLaCnp4eqVasiJCQEAHDgwAG4urpCX18fLi4uOHTokNL4s2fPhkKhwMWLF9GrVy8YGxvDxMQEQ4YMwcOHD5Xabt++HR06dIC1tTX09PTg7OyMKVOm4NmzZ0rtfH19YWhoiMuXL6NDhw4wMjJC27ZtpWFvnorYuXMnmjZtChMTE+jr66N69erw8/NTapOQkIAhQ4bAwsICOjo6cHZ2xuLFi5GTkyO1yT3U/+2332LJkiWoVq0aDA0N0bx5c/z+++8F/fNI/vrrL3Tv3h2mpqbQ1dVFgwYNsGHDBml4aGgoFAoFsrKysHLlSumwfWFMTEzQs2dPrF+/Xqn/+vXr0bJlS9SqVUvleEeOHEHbtm1hbGwMfX19tGzZEkePHpWGz549G5MmTQIAVKtWTarnxIkTAF6dXujatSv27NmDhg0bQldXF3PmzJGGvXlq7PHjx/j8889RvXp1abvr3Lkzrl69KrVZuXIl6tevD0NDQxgZGcHJyQnTpk0rdB2okpqaCmNjYxgaGqocnrtunZ2d0bx5c2zatAlZWVl5av7ll1/QvXt3VKpUSWlY+/btYWdnp7Tec3JysGHDBvj4+KBChcJ3qRMmTICBgQHS0tLyDOvfvz8sLS2RmZkJADh27Bg8PDxQqVIl6Onpwd7eHr1798bz588LnU9hirpPEEJgwYIFcHBwgK6uLho1aoSIiAh4eHjAw8NDaqfq1NjDhw8xcuRI2NnZQUdHB5UrV0bLli1x5MgRAK/2NwcOHMCdO3eUTlvlUnUa5/79+9I0tbW1YWNjgz59+uCff/4p9jowNjZGrVq18oz78uVLzJs3T1o3lStXxrBhw/Lsw168eIHPP/8cVlZW0NfXR+vWrREdHZ3nu5D7PT98+DD8/PxQuXJl6Ovr48WLFwBe7QubN28OAwMDGBoaomPHjrh48aLSvG7evIkBAwbAxsYGOjo6sLS0RNu2bRETEyO1Kcr2omqdFrafAv7v9PDWrVsxffp02NjYwNjYGO3atUN8fHxxV33Zou4kRsWXlZUl9PX1RdOmTYs8zsiRIwUAMXbsWHHo0CGxatUqUblyZWFnZycePnwotXN3dxeVKlUStWvXFj/++KMIDw8XXbt2FQDEnDlzhIuLi9i6dasICwsTzZo1Ezo6OuL+/fvS+EFBQQKAcHBwEJMmTRLh4eFiyZIlwsDAQDRs2FC8fPlSavvll1+KpUuXigMHDogTJ06IVatWiWrVqglPT0+l2n18fISWlpaoWrWqWLhwoTh69KgIDw+Xhr3+12RkZKRQKBRiwIABIiwsTBw7dkyEhIQIb29vqU1ycrKwtbUVlStXFqtWrRKHDh0SY8eOFQCUjsrcunVLABBVq1YVnTp1Env37hV79+4VLi4uwtTUVDx+/LjAdX716lVhZGQkHB0dxcaNG8WBAwfEwIEDBQDx9ddfS7WcPXtWABB9+vSRDtsXBIAICAgQR48eFQBEbGysEEKIR48eCV1dXbF+/XqVR3U2bdokFAqF6NGjh9izZ4/49ddfRdeuXYWGhoY4cuSIEEKIu3fvis8++0wAEHv27JHqefLkiRDi1V/V1tbWonr16mL9+vXi+PHj4ty5c9IwHx8faX5paWnio48+EgYGBmLu3LkiPDxc7N69W4wfP14cO3ZMCCHE1q1bBQDx2WeficOHD4sjR46IVatWiXHjxikts4ODQ5GOGsybN08AEAMHDhQnTpwo8GjVunXrBACxd+9epf7BwcECgDh06JDUL/eI0M6dO8XMmTOFjY2NyMrKEkIIcfDgQaFQKMSNGzeKdHTj0qVLAoBYu3atUv9Hjx4JHR0dERgYKIR4tf3p6uqK9u3bi71794oTJ06IzZs3C29vb/Ho0aMC51GUI0JF3SdMnTpVABAjR44Uhw4dEmvXrhX29vbC2tpauLu7S+1yvy8hISFSv44dO4rKlSuLNWvWiBMnToi9e/eKWbNmiW3btgkhhLhy5Ypo2bKlsLKykra117d/ACIoKEjqvnfvnrC2thbm5uZiyZIl4siRI2L79u3Cz89PxMXFFbi8qo4IZWZmCisrK+Hi4iL1y87OFp06dRIGBgZizpw5IiIiQqxbt07Y2tqKOnXqKG1TAwcOFBUqVBBTpkwRhw8fFsuWLRN2dnbCxMRE6bsQEhIiAAhbW1sxcuRIcfDgQbFr1y6RlZUl5s+fLxQKhfDz8xP79+8Xe/bsEc2bNxcGBgZKp25r164tatSoITZt2iROnjwpdu/eLT7//HNx/Phxaf0XZXt5c50WZT8lxP99B6pWrSoGDx4sDhw4ILZu3Srs7e1FzZo1pe9DecQgVA4lJSUJAGLAgAFFah8XFycAiDFjxij1/+OPPwQAMW3aNKmfu7u7ACDOnz8v9UtNTRUaGhpCT09PKfTExMQIAOL777+X+uUGoYkTJyrNa/PmzQKA+Omnn1TWmJOTIzIzM8XJkycFAHHp0iVpmI+PjwAg1q9fn2e8N4PQt99+KwAUGFKmTJkiAIg//vhDqf/o0aOFQqEQ8fHxQoj/27G7uLgofcnPnTsnAIitW7fmOw8hhBgwYIDQ0dERCQkJSv29vLyEvr6+Uo254aYoctvmXg/0v//9Twjx6gfc0NBQPH36NE8QevbsmTAzMxPdunVTmlZ2draoX7++aNKkidSvoFNjDg4OQkNDQ1pHbw57fec/d+5cAUBERETkuyxjx44VFStWLHSZHR0dhaOjY6HtMjIyRI8ePQQAAUBoaGiIhg0biunTp+e5duXp06fC0NBQfPLJJ0r93dzchJ2dncjOzpb6vR6Ecq8H2r9/vxBCiL59+woPDw8hRNFP87i6uooWLVoo9VuxYoUAIC5fviyEEGLXrl0CgIiJiSl0em8qLAgVdZ/w77//Ch0dHdG/f3+ldrnhvbAgZGhoKCZMmFBgrQWtszd/tP38/ISWlpYU/ovDwcFBdO7cWWRmZorMzExx584dMWLECKGlpSX9Wwrxf+F89+7dSuNHRUUJAGLFihVCiFchDoD44osvlNrljq8qCA0dOlSpbUJCgtDU1BSfffaZUv+nT58KKysr0a9fPyGEECkpKUrXrKlS1O3lzXVa1P1U7negc+fOSu127NghABT6B1xZxlNjMnD8+HEAyHPaokmTJnB2dlY6NQIA1tbWcHNzk7rNzMxgYWGBBg0awMbGRurv7OwMALhz506eeQ4ePFipu1+/ftDU1JRqAV4d6h00aBCsrKygoaEBLS0tuLu7A3h158+bevfuXeiyNm7cWJrfjh07cP/+/Txtjh07hjp16qBJkyZK/X19fSGEwLFjx5T6d+nSBRoaGlJ37p1Eqpb7zfm0bdsWdnZ2eebz/PlznD17ttDlKUjunWO5p3d+/PFH9OvXT+VpocjISPz777/w8fFBVlaW9MnJyUGnTp0QFRWV55RkfurVq5fvqbfXHTx4ELVq1UK7du3ybdOkSRM8fvwYAwcOxC+//IKUlBSV7W7cuIEbN24UOk8dHR38/PPPiI2NxdKlSzFgwAA8fPgQ8+fPh7Ozs9IhfENDQ/Tr1w9hYWHSqZG//voL0dHR8PX1zfc0V7Vq1eDh4YH169cjNTUVv/zyS55Tr4UZNmwYIiMjleoJCQlB48aNpbu9GjRoAG1tbYwcORIbNmzAzZs3izWPghR1n/D777/jxYsX6Nevn1K7Zs2aFenuuCZNmiA0NBTz5s3D77//Lp3ye1sHDx6Ep6entO8prrCwMGhpaUFLSwsODg5Yu3Ytli9fji5dukht9u/fj4oVK6Jbt25K35UGDRrAyspKOk188uRJAMizbvr06QNNTU2V839zHxYeHo6srCwMHTpUaV66urpwd3eX5mVmZgZHR0d88803WLJkCS5evKh0Gh94++2luPup1y+5AIq+PyzLGITKIXNzc+jr6+PWrVtFap+amgrgVcB5k42NjTQ8l5mZWZ522traefpra2sDADIyMvK0t7KyUurW1NREpUqVpHmlp6ejVatW+OOPPzBv3jycOHECUVFR2LNnDwDgv//+UxpfX18fxsbGBS4nALRu3Rp79+6Vdi5VqlRB3bp1sXXrVqlNampqvusid/jr3rxOJPearDdrfFNx5/M2cq9bWLBgAS5cuAB/f3+V7XJ/6Pv06SP9EOR+vv76awghivy4BVXLpMrDhw9RpUqVAtt4e3tj/fr1uHPnDnr37g0LCws0bdoUERERRZpHfpydnTFhwgT89NNPSEhIwJIlS5CamoqZM2cqtfP390dWVhY2bdoE4NU1VgqFAsOGDStw+v7+/vj111+xZMkS6OnpoU+fPsWqb/DgwdDR0ZGup4mNjUVUVJTSfB0dHXHkyBFYWFggICAAjo6OcHR0xHfffVesealS1H1C7n8tLS3ztFPV703bt2+Hj48P1q1bh+bNm8PMzAxDhw5FUlLSW9VdlG2qIB9//DGioqLw+++/Y9OmTahatSrGjh2L3377TWrzzz//4PHjx9DW1s7zXUlKSpLCen7rJndfp8qb6zv3e9m4ceM889q+fbs0L4VCgaNHj6Jjx45YtGgRXF1dUblyZYwbNw5Pnz4F8Pbby/vaH5ZlqmMrlWkaGhpo27YtDh48iHv37hW6Y8jdcBMTE/O0ffDgAczNzUu8xqSkJNja2krdWVlZSE1NlWo5duwYHjx4gBMnTkhHgQDk++yaolxAnKt79+7o3r07Xrx4gd9//x0LFy7EoEGDULVqVTRv3hyVKlVCYmJinvEePHgAACW2Pt7HfOzs7NCuXTvMmTMHtWvXRosWLVS2y53X8uXL831+TlF+2ICi/1tUrlw5z4W3qgwbNgzDhg3Ds2fPcOrUKQQFBaFr1664du0aHBwcijSvgigUCkycOBFz587FX3/9pTSsRYsWcHZ2RkhICMaPH4+ffvoJbdq0QbVq1QqcZq9evRAQEICvvvoKI0aMgJ6eXrFqMjU1Rffu3bFx40bMmzcPISEh0NXVxcCBA5XatWrVCq1atUJ2djbOnz+P5cuXY8KECbC0tMSAAQOKNc/XFXWfkNtO1YXISUlJhR4VMjc3x7Jly7Bs2TIkJCRg3759mDJlCpKTk/PcaFEURd2m8mNiYoJGjRoBAJo2bYqmTZuifv36GDNmDGJiYlChQgWYm5ujUqVK+dZnZGQEQHndqNrXqfLmdyd3Pe/atavQbd3BwQE//vgjAODatWvYsWMHZs+ejZcvX2LVqlUA3m57eV/7w7KMR4TKqalTp0IIgREjRuDly5d5hmdmZuLXX38F8OpBbwDw008/KbWJiopCXFycdAdWSdq8ebNS944dO5CVlSXdZZK7Q3jzjrfVq1eXWA06Ojpwd3fH119/DQDSXRht27ZFbGwsLly4oNR+48aNUCgU8PT0LJH5t23bVgp8b85HX1+/wAf6Fcfnn3+Obt265Tna8bqWLVuiYsWKiI2NRaNGjVR+co/wldRfeF5eXrh27VqeU435MTAwgJeXF6ZPn46XL1/iypUrxZ6nqh068GqnnpaWpnRqN5efnx9iY2MxY8YMPHz4sEinufT09DBr1ix069YNo0ePLnadwKsA+ODBA4SFheGnn35Cz549UbFiRZVtNTQ00LRpUwQHBwNAnm23uIq6T2jatCl0dHSwfft2pXa///57sU+F2NvbY+zYsWjfvr1S/To6OkXe1ry8vHD8+PESu0upZs2amDx5Mi5fviwtY9euXZGamors7GyV35PatWsDeHX0GUCedbNr1648dyLmp2PHjtDU1MTff/+d7/dSlVq1amHGjBlwcXFRuS0UZ3t5X/upsoxHhMqp5s2bY+XKlRgzZgzc3NwwevRofPTRR8jMzMTFixexZs0a1K1bF926dUPt2rUxcuRILF++HBUqVICXlxdu376NmTNnws7ODhMnTizx+vbs2QNNTU20b98eV65cwcyZM1G/fn3pfHqLFi1gamqKUaNGISgoCFpaWti8eTMuXbr0TvOdNWsW7t27h7Zt26JKlSp4/PgxvvvuO6XrjyZOnIiNGzeiS5cumDt3LhwcHHDgwAGsWLECo0ePLtL1L0URFBSE/fv3w9PTE7NmzYKZmRk2b96MAwcOYNGiRTAxMSmR+XTo0AEdOnQosI2hoSGWL18OHx8f/Pvvv+jTpw8sLCzw8OFDXLp0CQ8fPsTKlSsBAC4uLgCA7777Dj4+PtDS0kLt2rWlv4SLasKECdi+fTu6d++OKVOmoEmTJvjvv/9w8uRJdO3aFZ6entLRlJYtW8La2hpJSUlYuHAhTExMpOu9AKBGjRoAUOh1QiNHjsTjx4/Ru3dv1K1bFxoaGrh69SqWLl2KChUq4IsvvsgzztChQzFt2jR88803qFixInr16lWk5QsMDERgYGAx1oiyDh06oEqVKhgzZgySkpLynI5btWoVjh07hi5dusDe3h4ZGRnSbfsFXXeVKy0tDbt27crTv3LlynB3dy/SPsHMzAyBgYFYuHAhTE1N0bNnT9y7dw9z5syBtbV1gY8LePLkCTw9PTFo0CA4OTnByMgIUVFROHTokNI6dnFxwZ49e7By5Uq4ubmhQoUK+QaAuXPn4uDBg2jdujWmTZsGFxcXPH78GIcOHUJgYCCcnJwKXS9v+t///odVq1Zhzpw56NevHwYMGIDNmzejc+fOGD9+PJo0aQItLS3cu3cPx48fR/fu3dGzZ0989NFHGDhwIBYvXgwNDQ20adMGV65cweLFi2FiYlKkRylUrVoVc+fOxfTp03Hz5k106tQJpqam+Oeff3Du3DkYGBhgzpw5+PPPPzF27Fj07dsXNWvWhLa2No4dO4Y///wTU6ZMAfD228v72k+VaWq+WJveUUxMjPDx8RH29vZCW1tbuk191qxZSnfJZGdni6+//lrUqlVLaGlpCXNzczFkyJA8TxjN724TVbeeCpH3bqfcu8aio6NFt27dhKGhoTAyMhIDBw4U//zzj9K4kZGRonnz5kJfX19UrlxZDB8+XFy4cCHPnSc+Pj7CwMBA5fK/edfY/v37hZeXl7C1tRXa2trCwsJCdO7cWZw+fVppvDt37ohBgwaJSpUqCS0tLVG7dm3xzTffKN0plHsXzDfffKNyuV+/8yI/ly9fFt26dRMmJiZCW1tb1K9fX2nZXp9ece8aK0h+d36dPHlSdOnSRZiZmQktLS1ha2srunTpInbu3KnUburUqcLGxkZUqFBBAJBu0c1vO8gd9vqdMkK8uiV8/Pjxwt7eXmhpaQkLCwvRpUsXcfXqVSGEEBs2bBCenp7C0tJSaGtrCxsbG9GvXz/x559/5pl2Ue7GCg8PF35+fqJOnTrCxMREaGpqCmtra9GrV68C72rp2bOnyruocr1+11hBivtwwGnTpgkAee5SE+LVnVk9e/YUDg4OQkdHR1SqVEm4u7uLffv2FTrd3Ls/VX1y7/Qq6j4hJydHzJs3T1SpUkVoa2uLevXqif3794v69euLnj17Su3evGssIyNDjBo1StSrV08YGxsLPT09Ubt2bREUFKT0QNR///1X9OnTR1SsWFEoFArx+s+Squ/Z3bt3hZ+fn7CyshJaWlrSNvPm/uVNBW27uY9M2LBhgxDi1W313377rahfv77Q1dUVhoaGwsnJSXz66afi+vXr0ngZGRkiMDBQWFhYCF1dXdGsWTNx9uxZYWJionTnbO5dY1FRUSrnv3fvXuHp6SmMjY2Fjo6OcHBwEH369JEea/HPP/8IX19f4eTkJAwMDIShoaGoV6+eWLp0qXRHa1G3F1XrtCj7qfy+A6ruFixvFELI6CUrVOpmz56NOXPm4OHDh7I4t0wkR7du3YKTkxOCgoLe+uGXH6rIyEi0bNkSmzdvxqBBg9RdDhUBT40REVG+Ll26hK1bt6JFixYwNjZGfHw8Fi1aBGNj43zvUpSLiIgInD17Fm5ubtDT08OlS5fw1VdfoWbNmkU+xUrqxyBERET5MjAwwPnz5/Hjjz/i8ePHMDExgYeHB+bPn1/kOw0/VMbGxjh8+DCWLVuGp0+fwtzcHF5eXli4cCF0dXXVXR4VEU+NERERkWzx9nkiIiKSLQYhIiIiki0GISIiIpItXixdgJycHDx48ABGRkbFesUDERERqY8QAk+fPoWNjU2hD7dkECrAgwcP8ryRl4iIiMqHu3fvFvo+TgahAuS+UuDu3btFevM5ERERqV9aWhrs7OyK9GogBqEC5J4OMzY2ZhAiIiIqZ4pyWQsvliYiIiLZYhAiIiIi2WIQIiIiItniNUIlIDs7G5mZmeoug6hEaGlpQUNDQ91lEBG9FwxC70AIgaSkJDx+/FjdpRCVqIoVK8LKyorPzyKiDx6DkArBwcEIDg5GdnZ2ge1yQ5CFhQX09fX5o0HlnhACz58/R3JyMgDA2tpazRUREZUuvn2+AGlpaTAxMcGTJ0/y3D6fnZ2Na9euwcLCApUqVVJThUSlIzU1FcnJyahVqxZPkxFRuVPQ7/ebeLH0W8q9JkhfX1/NlRCVvNztmte+EdGHjkHoHfF0GH2IuF0TkVwwCBEREZFs8WLpUpCQkICUlJT3Nj9zc3PY29u/t/kRERF9KBiESlhCQgJq13ZGRsbz9zZPXV19xMfHFSsMJScnY+bMmTh48CD++ecfmJqaon79+pg2bRp69+6NCRMmYMaMGXnGW7hwIRYvXowHDx5gy5YtGDZsGJycnBAXF6fUbseOHejfvz8cHBxw+/btd11EIiKiUsEgVMJSUlL+fwj6CYDze5hjHDIyhiAlJaVYQah3797IzMzEhg0bUL16dfzzzz84evQo0tPTMWTIEISGhmL69Ol5rhUJCQmBt7c3tLW1AQAGBgZITk7G2bNn0bx5c6nd+vXreZSKiIjKPAahUuMMwFXdRaj0+PFj/Pbbbzhx4gTc3d0BAA4ODmjSpAkAwN7eHt999x1OnTolDQeA06dP4/r16/D395f6aWpqYtCgQVi/fr0UhO7du4cTJ05g4sSJ2Lp163tcMiKiD8P7vsRCndR9eQeDkAwZGhrC0NAQe/fuRbNmzaCjo6M03MXFBY0bN0ZISIhSEFq/fj2aNGmCunXrKrX39/dH69at8d1330FfXx+hoaHo1KkTLC0t38vyEBF9SBISEuDsVBvP/8tQdynvhb6eLuKuxqstDDEIyZCmpiZCQ0MxYsQIrFq1Cq6urnB3d8eAAQNQr149AICfnx/+97//4YcffoChoSHS09Oxc+dOLFmyJM/0GjRoAEdHR+zatQve3t4IDQ3FkiVLcPPmzfe9aERE5V5KSgqe/5eBn8YAzjbqrqZ0xT0AhqzIKPblHSWJQUimevfujS5duuD06dM4e/YsDh06hEWLFmHdunXw9fXFwIEDERgYiO3bt8Pf3x/bt2+HEAIDBgxQOT0/Pz+EhITA3t4e6enp6Ny5M3744Yf3vFRE9KGTwymj3JtPnG0A12pqLkYGGIRkTFdXF+3bt0f79u0xa9YsDB8+HEFBQfD19YWJiQn69OmDkJAQ+Pv7IyQkBH369Mn3UeWDBw/G5MmTMXv2bAwdOhSamty0iKhkqeOuXPrw8deKJHXq1MHevXulbn9/f3h4eGD//v04c+YMFixYkO+4ZmZm+OSTT7Bjxw6sWrXqPVRLRHLz/u/KVZcwADPVXYRsMAjJUGpqKvr27Qs/Pz/Uq1cPRkZGOH/+PBYtWoTu3btL7dzd3VGjRg0MHToUNWrUQOvWrQucbmhoKFasWMGX0BJRKSu7d+WWjLjCm1CJYRAqNe9rQy7+fAwNDdG0aVMsXboUf//9NzIzM2FnZ4cRI0Zg2rRpSm39/Pwwbdo0TJo0qdDp6unpQU9Pr9j1EBERqYtCCCHUXURZlZaWBhMTEzx58iTPtTEZGRm4desWqlWrBl1dXal/eXmyNFFB8tu+idTpwoULcHNzAxCND/uI0GYAQxA978O/WPrCLcBtBhAdHQ1X15L7Ny3o9/tNPCKkQnBwMIKDg5GdnV3sce3t7REfH8d3jREREZUDDEIqBAQEICAgQEqUxWVvb89gQkREVA5UUHcBREREROrCIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLF5wiVgoSEBNk/ULFq1aqYMGECJkyY8Fbjh4aGYsKECXj8+HGJ1vUh8PDwQIMGDbBs2TJ1l0JEVO4xCJWwhIQEODvVxvP/Mt7bPPX1dBF3Nb7IYcjX1xePHz9WetN8SYuKioKBgUGR2qoKTf3790fnzp3fev6hoaEYNmyY1G1hYYEmTZrgq6++wkcfffTW0y0L9uzZAy0tLXWXQUT0QWAQKmEpKSl4/l8GfhoDONuU/vziHgBDVmQgJSWlTB0Vqly58juNXxIvcDU2NkZ8fDyEELh//z4mT56MLl264Nq1a9DW1n6naRckMzOzVIOKmZlZqU2biEhueI1QKXG2efWyvNL+lEbYOnnyJJo0aQIdHR1YW1tjypQpyMrKkoY/ffoUgwcPhoGBAaytrbF06VJ4eHgoHdGpWrWq0qmb2bNnw97eHjo6OrCxscG4ceMAvDrNc+fOHUycOBEKhQIKhQLAqyM6FStWVKpr3759aNSoEXR1dWFubo5evXoVuBwKhQJWVlawtrZGo0aNMHHiRNy5cwfx8fFSm8jISLRu3Rp6enqws7PDuHHj8OzZM2l4YmIiunTpAj09PVSrVg1btmzJs2wKhQKrVq1C9+7dYWBggHnz5gEAfv31V7i5uUFXVxfVq1fHnDlzlNZjfusEAFasWIGaNWtCV1cXlpaW6NOnjzTszXX96NEjDB06FKamptDX14eXlxeuX78uDc9dl+Hh4XB2doahoSE6deqExMTEAtcfEZEcMAiRkvv376Nz585o3LgxLl26hJUrV+LHH3+UftwBIDAwEGfOnMG+ffsQERGB06dP48KFC/lOc9euXVi6dClWr16N69evY+/evXBxcQHw6jRPlSpVMHfuXCQmJub743zgwAH06tULXbp0wcWLF3H06FE0atSoyMv1+PFjbNmyBQCkozWXL19Gx44d0atXL/z555/Yvn07fvvtN4wdO1Yab+jQoXjw4AFOnDiB3bt3Y82aNUhOTs4z/aCgIHTv3h2XL1+Gn58fwsPDMWTIEIwbNw6xsbFYvXo1QkNDMX/+/ELXyfnz5zFu3DjMnTsX8fHxOHToEFq3bp3vsvn6+uL8+fPYt28fzp49CyEEOnfujMzMTKnN8+fP8e2332LTpk04deoUEhIS8L///a/I64+I6EPFU2OkZMWKFbCzs8MPP/wAhUIBJycnPHjwAF988QVmzZqFZ8+eYcOGDdiyZQvatm0LAAgJCYGNTf6HphISEmBlZYV27dpBS0sL9vb2aNKkCYBXp3k0NDRgZGQEKyurfKcxf/58DBgwAHPmzJH61a9fv8BlefLkCQwNDSGEwPPnzwEAn3zyCZycnAAA33zzDQYNGiQdXalZsya+//57uLu7Y+XKlbh9+zaOHDmCqKgoKXStW7cONWvWzDOvQYMGwc/PT+r29vbGlClT4OPjAwCoXr06vvzyS0yePBlBQUEFrpOEhAQYGBiga9euMDIygoODAxo2bKhyGa9fv459+/bhzJkzaNGiBQBg8+bNsLOzw969e9G3b18Ar07XrVq1Co6OjgCAsWPHYu7cuQWuPyIiOeARIVISFxeH5s2bS6eoAKBly5ZIT0/HvXv3cPPmTWRmZko/2gBgYmKC2rVr5zvNvn374r///kP16tUxYsQI/Pzzz0qniIoiJiZGCl5FZWRkhJiYGERHR0shYNWqVdLw6OhohIaGwtDQUPp07NgROTk5uHXrFuLj46GpqQlXV1dpnBo1asDU1DTPvN48OhUdHY25c+cqTXvEiBFITEzE8+fPC1wn7du3h4ODA6pXrw5vb29s3rxZCnJviouLg6amJpo2bSr1q1SpEmrXro24uDipn76+vhSCAMDa2lrlkS0iIrlhECIlQgilEJTbD3h1Lczr/6+qjSp2dnaIj49HcHAw9PT0MGbMGLRu3Vrp1E1h3ubC6QoVKqBGjRpwcnLCp59+Cm9vb/Tv318anpOTg08//RQxMTHS59KlS7h+/TocHR3zXSZV/d+8Qy4nJwdz5sxRmvbly5dx/fp16OrqFrhOjIyMcOHCBWzduhXW1taYNWsW6tevr/JRAgXV+Pq/0ZsXb7/+b0lEJGcMQqSkTp06iIyMVPqRjIyMhJGREWxtbeHo6AgtLS2cO3dOGp6WlqZ0ca4qenp6+OSTT/D999/jxIkTOHv2LC5fvgwA0NbWRnZ2doHj16tXD0ePHn2HJQMmTpyIS5cu4eeffwYAuLq64sqVK6hRo0aej7a2NpycnJCVlYWLFy9K07hx40aRnm3k6uqK+Ph4ldOuUOHV166gdaKpqYl27dph0aJF+PPPP3H79m0cO3Ysz3zq1KmDrKws/PHHH1K/1NRUXLt2Dc7Ozu+yuoiIZIHXCMnUkydPEBMTo9TPzMwMY8aMwbJly/DZZ59h7NixiI+PR1BQEAIDA1GhQgUYGRnBx8cHkyZNgpmZGSwsLBAUFIQKFSrkOUqUKzQ0FNnZ2WjatCn09fWxadMm6OnpwcHBAcCrO8xOnTqFAQMGQEdHB+bm5nmmERQUhLZt28LR0REDBgxAVlYWDh48iMmTJxd5mY2NjTF8+HAEBQWhR48e+OKLL9CsWTMEBARgxIgRMDAwQFxcHCIiIrB8+XI4OTmhXbt2GDlyJFauXAktLS18/vnn0NPTy3dZc82aNQtdu3aFnZ0d+vbtiwoVKuDPP//E5cuXMW/evALXyf79+3Hz5k20bt0apqamCAsLQ05OjsrTjzVr1kT37t0xYsQIrF69GkZGRpgyZQpsbW3RvXv3Iq8bIiK5YhAqJXEPyvZ8Tpw4kecCXB8fH4SGhiIsLAyTJk1C/fr1YWZmBn9/f8yYMUNqt2TJEowaNQpdu3aFsbExJk+ejLt370JXV1flvCpWrIivvvoKgYGByM7OhouLC3799VdUqlQJADB37lx8+umncHR0xIsXL1SesvHw8MDOnTvx5Zdf4quvvoKxsXGBd1LlZ/z48fj++++xc+dO9OvXDydPnsT06dPRqlUrCCHg6OiodPps48aN8Pf3R+vWrWFlZYWFCxfiypUr+S5rro4dO2L//v2YO3cuFi1aBC0tLTg5OWH48OGFrpOKFStiz549mD17NjIyMlCzZk1s3bo13wdBhoSEYPz48ejatStevnyJ1q1bIywsjA9dJCIqAoXghQL5SktLg4mJCZ48eQJjY2OlYRkZGbh16xaqVaum9KNYHp4sXdKePXsGW1tbLF68GP7+/mqp4X25d+8e7OzscOTIkWJfvF2e5Ld9E6nThQsX4ObmBiAagGthzcuxzQCGIHreq+fFfcgu3ALcZry6weT1G1PeVUG/32/iEaESZm9vj7ir8R/0u8YuXryIq1evokmTJnjy5Il0G/aHeCrm2LFjSE9Ph4uLCxITEzF58mRUrVr1rY5GERFR2cMgVArs7e3L1OsuSsO3336L+Ph4aGtrw83NDadPn1Z5bU95l5mZiWnTpuHmzZswMjJCixYtsHnzZp52IiL6QHzwQeju3bvw9vZGcnIyNDU1MXPmTOkhc/R2GjZsiOjoaHWX8V507NgRHTt2VHcZRERUSj74IKSpqYlly5ahQYMGSE5OhqurKzp37lzkN6MTERHRh+uDD0LW1tawtrYGAFhYWMDMzAz//vtviQUhXmtOHyJu10QkF2X+gYqnTp1Ct27dYGNjA4VCgb179+Zps2LFCunultzrVVQ5f/48cnJyYGdn98515V4jkt+rD4jKs9ztmtdCEdGHrswfEXr27Bnq16+PYcOGoXfv3nmGb9++HRMmTMCKFSvQsmVLrF69Gl5eXoiNjVW6YDk1NRVDhw7FunXrSqQuDQ0NVKxYUXpfk76+fqEP2SMq63JfUJucnIyKFStCQ0ND3SUREZWqMh+EvLy84OXlle/wJUuWwN/fX3pQ3bJlyxAeHo6VK1di4cKFAIAXL16gZ8+emDp1qvSGblVevHiBFy9eSN1paWkF1pb7tnS+vJI+NBUrVpS2byKiD1mZD0IFefnyJaKjozFlyhSl/h06dEBkZCSAV3/h+vr6ok2bNvD29i5wegsXLsScOXOKPH+FQgFra2tYWFgU6wWiRGWZlpYWjwQRkWyU6yCUkpKC7OxsWFpaKvW3tLREUlISAODMmTPYvn076tWrJ11ftGnTJri4uOSZ3tSpUxEYGCh1p6WlFel6Ig0NDf5wEBERlUPlOgjlevPaHCGE1O/jjz9GTk5Okaajo6MDHR2dEq+PiIiIyqYyf9dYQczNzaGhoSEd/cmVnJyc5ygRERER0ZvKdRDKfb1DRESEUv+IiIgCL4omIiIiAsrBqbH09HTcuHFD6r516xZiYmJgZmYGe3t7BAYGwtvbG40aNULz5s2xZs0aJCQkYNSoUW89z+DgYAQHByM7O7skFoGIiIjKqDIfhM6fPw9PT0+pO/diZh8fH4SGhqJ///5ITU3F3LlzkZiYiLp16yIsLAwODg5vPc+AgAAEBAQgLS0NJiYm77wMREREVDaV+SDk4eFR6OP+x4wZgzFjxrynioiIiOhDUa6vESIiIiJ6FwxCREREJFsMQioEBwejTp06aNy4sbpLISIiolLEIKRCQEAAYmNjERUVpe5SiIiIqBQxCBEREZFsMQgRERGRbDEIERERkWwxCKnAi6WJiIjkgUFIBV4sTUREJA8MQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCKvD2eSIiInlgEFKBt88TERHJA4MQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoOQCnyOEBERkTwwCKnA5wgRERHJA4MQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDkAp8oCIREZE8MAipwAcqEhERyQODEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWg5AKfNcYERGRPDAIqcB3jREREckDgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoOQCsHBwahTpw4aN26s7lKIiIioFDEIqRAQEIDY2FhERUWpuxQiIiIqRQxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkW7IIQj179oSpqSn69Omj7lKIiIioDJFFEBo3bhw2btyo7jKIiIiojJFFEPL09ISRkZG6yyAiIqIypswHoVOnTqFbt26wsbGBQqHA3r1787RZsWIFqlWrBl1dXbi5ueH06dPvv1AiIiIqd8p8EHr27Bnq16+PH374QeXw7du3Y8KECZg+fTouXryIVq1awcvLCwkJCe+5UiIiIipvNNVdQGG8vLzg5eWV7/AlS5bA398fw4cPBwAsW7YM4eHhWLlyJRYuXFiseb148QIvXryQutPS0t6uaCIiIioXyvwRoYK8fPkS0dHR6NChg1L/Dh06IDIystjTW7hwIUxMTKSPnZ1dSZVKREREZVC5DkIpKSnIzs6GpaWlUn9LS0skJSVJ3R07dkTfvn0RFhaGKlWqICoqSuX0pk6diidPnkifu3fvlmr9REREpF5l/tRYUSgUCqVuIYRSv/Dw8CJNR0dHBzo6OiVaGxEREZVd5fqIkLm5OTQ0NJSO/gBAcnJynqNERERERG8q10FIW1sbbm5uiIiIUOofERGBFi1avPV0g4ODUadOHTRu3PhdSyQiIqIyrMyfGktPT8eNGzek7lu3biEmJgZmZmawt7dHYGAgvL290ahRIzRv3hxr1qxBQkICRo0a9dbzDAgIQEBAANLS0mBiYlISi0FERERlUJkPQufPn4enp6fUHRgYCADw8fFBaGgo+vfvj9TUVMydOxeJiYmoW7cuwsLC4ODgoK6SiYiIqJwo80HIw8MDQogC24wZMwZjxox5TxURERHRh6JcXyNERERE9C4YhFTgxdJERETywCCkQkBAAGJjY/N98CIRERF9GBiEiIiISLYYhIiIiEi2ih2E7t69i3v37knd586dw4QJE7BmzZoSLYyIiIiotBU7CA0aNAjHjx8HACQlJaF9+/Y4d+4cpk2bhrlz55Z4gURERESlpdhB6K+//kKTJk0AADt27EDdunURGRmJLVu2IDQ0tKTrUwveNUZERCQPxQ5CmZmZ0hvajxw5gk8++QQA4OTkhMTExJKtTk141xgREZE8FDsIffTRR1i1ahVOnz6NiIgIdOrUCQDw4MEDVKpUqcQLJCIiIiotxQ5CX3/9NVavXg0PDw8MHDgQ9evXBwDs27dPOmVGREREVB4U+11jHh4eSElJQVpaGkxNTaX+I0eOhL6+fokWR0RERFSa3uo5QkIIREdHY/Xq1Xj69CkAQFtbm0GIiIiIypViHxG6c+cOOnXqhISEBLx48QLt27eHkZERFi1ahIyMDKxatao06iQiIiIqccU+IjR+/Hg0atQIjx49gp6entS/Z8+eOHr0aIkWpy68fZ6IiEgein1E6LfffsOZM2egra2t1N/BwQH3798vscLUKSAgAAEBAUhLS4OJiYm6yyEiIqJSUuwjQjk5OcjOzs7T/969ezAyMiqRooiIiIjeh2IHofbt22PZsmVSt0KhQHp6OoKCgtC5c+eSrI2IiIioVBX71NjSpUvh6emJOnXqICMjA4MGDcL169dhbm6OrVu3lkaNRERERKWi2EHIxsYGMTEx2Lp1Ky5cuICcnBz4+/tj8ODBShdPExEREZV1xQ5CAKCnpwc/Pz/4+fmVdD1ERO9NQkICUlJS1F3Ge2Fubg57e3t1l0FU5hQ7CG3cuLHA4UOHDn3rYsqK4OBgBAcHq7wonIg+DAkJCXB2qo3n/2Wou5T3Ql9PF3FX4xmGiN5Q7CA0fvx4pe7MzEw8f/5cerL0hxCEePs80YcvJSUFz//LwE9jAGcbdVdTuuIeAENWZCAlJYVBiOgNxQ5Cjx49ytPv+vXrGD16NCZNmlQiRRERvS/ONoBrNXVXQUTq8lbXCL2pZs2a+OqrrzBkyBBcvXq1JCZJRGokh2tn4uLi1F0CEZUBJRKEAEBDQwMPHjwoqckRkZokJCSgdm1nZGQ8V3cpRESlrthBaN++fUrdQggkJibihx9+QMuWLUusMCJSj5SUlP8fgn4C4KzuckpRGICZ6i6CiNSs2EGoR48eSt0KhQKVK1dGmzZtsHjx4pKqi4jUzhmAq7qLKEU8NUZEbxGEcnJySqMOIiIioveu2O8aIyIiIvpQFOmIUGBgYJEnuGTJkrcuhoiIiOh9KlIQunjxYpEmplAo3qmYsoJPliYiIpKHIgWh48ePl3YdZQqfLE1ERCQPvEaIiIiIZOutHqgYFRWFnTt3IiEhAS9fvlQatmfPnhIpjIiIiKi0FfuI0LZt29CyZUvExsbi559/RmZmJmJjY3Hs2DGeRiIiIqJypdhBaMGCBVi6dCn2798PbW1tfPfdd4iLi0O/fv34VmMiIiIqV4odhP7++2906dIFAKCjo4Nnz55BoVBg4sSJWLNmTYkXSERERFRaih2EzMzM8PTpUwCAra0t/vrrLwDA48eP8fw5X9JIRERE5UeRg1BMTAwAoFWrVoiIiAAA9OvXD+PHj8eIESMwcOBAtG3btlSKJCIiIioNRb5rzNXVFQ0bNkSPHj0wcOBAAMDUqVOhpaWF3377Db169cLMmXyTMxEREZUfRT4idObMGbi6uuLbb7+Fo6MjhgwZgpMnT2Ly5MnYt28flixZAlNT09KslYiIiKhEFTkINW/eHGvXrkVSUhJWrlyJe/fuoV27dnB0dMT8+fNx79690qyTiIiIqMQV+2JpPT09+Pj44MSJE7h27RoGDhyI1atXo1q1aujcuXNp1PjeBQcHo06dOmjcuLG6SyEiIqJS9E6v2HB0dMSUKVMwffp0GBsbIzw8vKTqUquAgADExsYiKipK3aUQERFRKXqrV2wAwMmTJ7F+/Xrs3r0bGhoa6NevH/z9/UuyNiIiIqJSVawgdPfuXYSGhiI0NBS3bt1CixYtsHz5cvTr1w8GBgalVSMRERFRqShyEGrfvj2OHz+OypUrY+jQofDz80Pt2rVLszYiIiKiUlXkIKSnp4fdu3eja9eu0NDQKM2aiIiIiN6LIgehffv2lWYdRERERO/dO901RkRERFSeMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQipEBwcjDp16qBx48bqLoWIiIhKEYOQCgEBAYiNjUVUVJS6SyEiIqJSxCBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESy9cEHof3796N27dqoWbMm1q1bp+5yiIiIqAzRVHcBpSkrKwuBgYE4fvw4jI2N4erqil69esHMzEzdpREREVEZ8EEfETp37hw++ugj2NrawsjICJ07d0Z4eLi6yyIiIqIyokwHoVOnTqFbt26wsbGBQqHA3r1787RZsWIFqlWrBl1dXbi5ueH06dPSsAcPHsDW1lbqrlKlCu7fv/8+SiciIqJyoEwHoWfPnqF+/fr44YcfVA7fvn07JkyYgOnTp+PixYto1aoVvLy8kJCQAAAQQuQZR6FQlGrNREREVH6U6WuEvLy84OXlle/wJUuWwN/fH8OHDwcALFu2DOHh4Vi5ciUWLlwIW1tbpSNA9+7dQ9OmTfOd3osXL/DixQupOy0trQSWgoiIiMqqMn1EqCAvX75EdHQ0OnTooNS/Q4cOiIyMBAA0adIEf/31F+7fv4+nT58iLCwMHTt2zHeaCxcuhImJifSxs7Mr1WUgIiIi9Sq3QSglJQXZ2dmwtLRU6m9paYmkpCQAgKamJhYvXgxPT080bNgQkyZNQqVKlfKd5tSpU/HkyRPpc/fu3VJdBiIiIlKvMn1qrCjevOZHCKHU75NPPsEnn3xSpGnp6OhAR0enROsjIiKisqvcHhEyNzeHhoaGdPQnV3Jycp6jRERERESqlNsgpK2tDTc3N0RERCj1j4iIQIsWLdRUFREREZUnZfrUWHp6Om7cuCF137p1CzExMTAzM4O9vT0CAwPh7e2NRo0aoXnz5lizZg0SEhIwatSod5pvcHAwgoODkZ2d/a6LQERERGVYmQ5C58+fh6enp9QdGBgIAPDx8UFoaCj69++P1NRUzJ07F4mJiahbty7CwsLg4ODwTvMNCAhAQEAA0tLSYGJi8k7TIiIiorKrTAchDw8PlQ9FfN2YMWMwZsyY91QRERERfUjK7TVCRERERO+KQYiIiIhki0FIheDgYNSpUweNGzdWdylERERUihiEVAgICEBsbCyioqLUXQoRERGVIgYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GIRV41xgREZE8MAipwLvGiIiI5IFBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQUgF3jVGREQkDwxCKvCuMSIiInlgECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliEFKBzxEiIiKSBwYhFfgcISIiInlgECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhBSgQ9UJCIikgcGIRX4QEUiIiJ5YBAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQUoHvGiMiIpIHBiEV+K4xIiIieWAQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliEFIhODgYderUQePGjdVdChEREZUiBiEVAgICEBsbi6ioKHWXQkRERKWIQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZEtT3QXIWUJCAlJSUtRdRqkzNzeHvb29ussgIiLKg0FITRISElC7tjMyMp6ru5RSp6urj/j4OIYhIiIqcxiE1CQlJeX/h6CfADiru5xSFIeMjCFISUlhECIiojKHQUjtnAG4qrsIIiIiWeLF0kRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFuyCEI9e/aEqakp+vTpo+5SiIiIqAyRRRAaN24cNm7cqO4yiIiIqIyRRRDy9PSEkZGRussgIiKiMkbtQejUqVPo1q0bbGxsoFAosHfv3jxtVqxYgWrVqkFXVxdubm44ffr0+y+UiIiIPjhqD0LPnj1D/fr18cMPP6gcvn37dkyYMAHTp0/HxYsX0apVK3h5eSEhIUFq4+bmhrp16+b5PHjw4H0tBhEREZVDmuouwMvLC15eXvkOX7JkCfz9/TF8+HAAwLJlyxAeHo6VK1di4cKFAIDo6OgSqeXFixd48eKF1J2WllYi0yUiIqKySe1HhAry8uVLREdHo0OHDkr9O3TogMjIyBKf38KFC2FiYiJ97OzsSnweREREVHaU6SCUkpKC7OxsWFpaKvW3tLREUlJSkafTsWNH9O3bF2FhYahSpQqioqJUtps6dSqePHkife7evftO9RMREVHZpvZTY0WhUCiUuoUQefoVJDw8vEjtdHR0oKOjU6zaiIiIqPwq00eEzM3NoaGhkefoT3Jycp6jRERERETFVaaDkLa2Ntzc3BAREaHUPyIiAi1atCi1+QYHB6NOnTpo3Lhxqc2DiIiI1E/tp8bS09Nx48YNqfvWrVuIiYmBmZkZ7O3tERgYCG9vbzRq1AjNmzfHmjVrkJCQgFGjRpVaTQEBAQgICEBaWhpMTExKbT5yEhcXp+4S3gtzc3PY29uruwwiIioitQeh8+fPw9PTU+oODAwEAPj4+CA0NBT9+/dHamoq5s6di8TERNStWxdhYWFwcHBQV8lULImooACGDBmi7kLeC309XcRdjWcYIiIqJ9QehDw8PCCEKLDNmDFjMGbMmPdUEZWsx8gRwE9jAGcbdddSuuIeAENWZCAlJYVBiIionFB7ECJ5cLYBXKupuwoiIiJlZfpiaXXhxdJERETywCCkQkBAAGJjY/N98CIRERF9GBiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhFTgXWNERETywCCkAu8aIyIikgcGISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLb59XoXg4GAEBwcjKysLAJCWllbi80hPT8/9PwAlP/2y4zkAID0DSHuu5lJKWXrG//9venqpbDPvC7fNDw+3zfKG2+a7yp2WEKLQtgpRlFYyde/ePdjZ2am7DCIiInoLd+/eRZUqVQpswyBUgJycHDx48ABGRkZQKBTqLqdcSktLg52dHe7evQtjY2N1l0Mk4bZJZRW3zXcnhMDTp09hY2ODChUKvgqIp8YKUKFChUKTJBWNsbExv9BUJnHbpLKK2+a7MTExKVI7XixNREREssUgRERERLLFIESlSkdHB0FBQdDR0VF3KURKuG1SWcVt8/3ixdJEREQkWzwiRERERLLFIERERESyxSBEREREssUgRETlioeHByZMmKDuMiS3b9+GQqFATEyMukuhYvD19UWPHj2k7qJsV1WrVsWyZctKta6SplAosHfvXnWXUaYxCMlQZGQkNDQ00KlTJ3WXQmr05g9BrhMnTkChUODx48fvvaai2LNnD7788stSn4+HhwcUCgUUCgV0dHRga2uLbt26Yc+ePUrt7OzskJiYiLp16xY6TYamovH19ZXW/euf0txnva/tqiS8vn60tLRgaWmJ9u3bY/369cjJyVFqm5iYCC8vryJNV66hiUFIhtavX4/PPvsMv/32GxISEtRWR2ZmptrmTeWXmZkZjIyM3su8RowYgcTERNy4cQO7d+9GnTp1MGDAAIwcOVJqo6GhASsrK2hq8kH9JalTp05ITExU+mzdurXU5vc+t6uSkLt+bt++jYMHD8LT0xPjx49H165dpReGA4CVlRVvwy8Eg5DMPHv2DDt27MDo0aPRtWtXhIaGKg3ft28fGjVqBF1dXZibm6NXr17SsBcvXmDy5Mmws7ODjo4OatasiR9//BEAEBoaiooVKypNa+/evUrvaJs9ezYaNGiA9evXo3r16tDR0YEQAocOHcLHH3+MihUrolKlSujatSv+/vtvpWndu3cPAwYMgJmZGQwMDNCoUSP88ccfuH37NipUqIDz588rtV++fDkcHByK9OZhKlhqaioGDhyIKlWqQF9fHy4uLnl+kDw8PPDZZ59hwoQJMDU1haWlJdasWYNnz55h2LBhMDIygqOjIw4ePCiNk3vkKTw8HA0bNoSenh7atGmD5ORkHDx4EM7OzjA2NsbAgQPx/PlzpXm9fgqjatWqWLBgAfz8/GBkZAR7e3usWbNGqb7IyEg0aNAAurq6aNSokbRtFnZkRl9fH1ZWVrCzs0OzZs3w9ddfY/Xq1Vi7di2OHDkCIO9RnkePHmHw4MGoXLky9PT0ULNmTYSEhAAAqlWrBgBo2LAhFAoFPDw8AABRUVFo3749zM3NYWJiAnd3d1y4cEGpFoVCgXXr1qFnz57Q19dHzZo1sW/fPqU2V65cQZcuXWBsbAwjIyO0atVK6bsUEhICZ2dn6OrqwsnJCStWrChw+dVJR0cHVlZWSh9TU1MAqo+sPX78GAqFAidOnJD6FbY+XvfmdpWcnIxu3bpBT08P1apVw+bNm/OM8+TJE4wcORIWFhYwNjZGmzZtcOnSJWn433//je7du8PS0hKGhoZo3LixtN3kKsr2W9D6sbW1haurK6ZNm4ZffvkFBw8eVNqvv36U5+XLlxg7diysra2hq6uLqlWrYuHChVIdANCzZ08oFAqpu6SWIb99eK5ff/0Vbm5u0NXVRfXq1TFnzhylQFeaGIRkZvv27ahduzZq166NIUOGICQkRAoLBw4cQK9evdClSxdcvHgRR48eRaNGjaRxhw4dim3btuH7779HXFwcVq1aBUNDw2LN/8aNG9ixYwd2794t7cSePXuGwMBAREVF4ejRo6hQoQJ69uwpHeJNT0+Hu7s7Hjx4gH379uHSpUuYPHkycnJyULVqVbRr1076ockVEhIiHT6md5ORkQE3Nzfs378ff/31F0aOHAlvb2+lnRgAbNiwAebm5jh37hw+++wzjB49Gn379kWLFi1w4cIFdOzYEd7e3kqhBngVkH/44QdERkbi7t276NevH5YtW4YtW7bgwIEDiIiIwPLlywuscfHixWjUqBEuXryIMWPGYPTo0bh69SoA4OnTp+jWrRtcXFxw4cIFfPnll/jiiy/een34+PjA1NQ0zymyXDNnzkRsbCwOHjyIuLg4rFy5Eubm5gCAc+fOAQCOHDmCxMREaRpPnz6Fj48PTp8+jd9//x01a9ZE586d8fTpU6Vpz5kzB/369cOff/6Jzp07Y/Dgwfj3338BAPfv30fr1q2hq6uLY8eOITo6Gn5+ftKPydq1azF9+nTMnz8fcXFxWLBgAWbOnIkNGza89booywpbH4Xx9fXF7du3cezYMezatQsrVqxAcnKyNFwIgS5duiApKQlhYWGIjo6Gq6sr2rZtK/2bpKeno3Pnzjhy5AguXryIjh07olu3bnmOxBe0/RZHmzZtUL9+/Xy3ze+//x779u3Djh07EB8fj59++kkKPFFRUQBe7TsTExOl7pJYhoL24QAQHh6OIUOGYNy4cYiNjcXq1asRGhqK+fPnF3sdvBVBstKiRQuxbNkyIYQQmZmZwtzcXERERAghhGjevLkYPHiwyvHi4+MFAKntm0JCQoSJiYlSv59//lm8vokFBQUJLS0tkZycXGCNycnJAoC4fPmyEEKI1atXCyMjI5Gamqqy/fbt24WpqanIyMgQQggRExMjFAqFuHXrVoHzkTsfHx+hoaEhDAwMlD66uroCgHj06FG+43bu3Fl8/vnnUre7u7v4+OOPpe6srCxhYGAgvL29pX6JiYkCgDh79qwQQojjx48LAOLIkSNSm4ULFwoA4u+//5b6ffrpp6Jjx45K8xo/frzU7eDgIIYMGSJ15+TkCAsLC7Fy5UohhBArV64UlSpVEv/995/UZu3atQKAuHjxYr7L+OZ8Xte0aVPh5eUlhBDi1q1bStPq1q2bGDZsmMrx3mybn6ysLGFkZCR+/fVXqR8AMWPGDKk7PT1dKBQKcfDgQSGEEFOnThXVqlUTL1++VDlNOzs7sWXLFqV+X375pWjevHmBtahDftvm3LlzhRCq1+OjR48EAHH8+HEhROHrw8fHR3Tv3l3qfv3fO3d/9/vvv0vD4+LiBACxdOlSIYQQR48eFcbGxtJ+J5ejo6NYvXp1vstWp04dsXz5cqm7sO23KLW/rn///sLZ2VnqBiB+/vlnIYQQn332mWjTpo3IyclROe7rbQtS3GUobB/eqlUrsWDBAqV+mzZtEtbW1oXWUhJ4REhG4uPjce7cOQwYMAAAoKmpif79+2P9+vUAgJiYGLRt21bluDExMdDQ0IC7u/s71eDg4IDKlSsr9fv7778xaNAgVK9eHcbGxtLpg9y/OGJiYtCwYUOYmZmpnGaPHj2gqamJn3/+GcCra6A8PT2lv3Qof56enoiJiVH6rFu3TqlNdnY25s+fj3r16qFSpUowNDTE4cOH8/xFWK9ePen/NTQ0UKlSJbi4uEj9LC0tAUDpr+o3x7O0tIS+vj6qV6+u1O/Ncd70+jQUCgWsrKykceLj41GvXj3o6upKbZo0aVLg9AojhMj3aOPo0aOxbds2NGjQAJMnT0ZkZGSh00tOTsaoUaNQq1YtmJiYwMTEBOnp6QWuYwMDAxgZGUnLGRMTg1atWkFLSyvP9B8+fIi7d+/C398fhoaG0mfevHn5nipSN1XbZkBAQJHHL2h9FCYuLg6amppKR8SdnJyUTv9HR0cjPT1d+k7kfm7duiWt02fPnmHy5MmoU6cOKlasCENDQ1y9erXAf9c3t9/iKmjb9PX1RUxMDGrXro1x48bh8OHDhU6vJJahsH14dHQ05s6dq7Qec6/Pe/MIcmng1X0y8uOPPyIrKwu2trZSPyEEtLS08OjRI+jp6eU7bkHDAKBChQp5rsdRdTG0gYFBnn7dunWDnZ0d1q5dCxsbG+Tk5KBu3bp4+fJlkeatra0Nb29vhISEoFevXtiyZUu5u8VVXQwMDFCjRg2lfvfu3VPqXrx4MZYuXYply5bBxcUFBgYGmDBhgvTvk+vNH5zcO1pe7waQ566WN9uoms6b47ypoHFU/TC8ua0WR3Z2Nq5fv47GjRurHO7l5YU7d+7gwIEDOHLkCNq2bYuAgAB8++23+U7T19cXDx8+xLJly+Dg4AAdHR00b968SOs4dzkL+p7ktlm7di2aNm2qNExDQyP/hVUjVdtmrgoVXv0N//q/45v7m8L2GwXJnW5Bp9ZzcnJgbW2tdE1SrtzANGnSJISHh+Pbb79FjRo1oKenhz59+hTr37W44uLipD8m3+Tq6opbt27h4MGDOHLkCPr164d27dph165d+U6vJJahsH+LnJwczJkzR+ma1Fyv/wFTWhiEZCIrKwsbN27E4sWL0aFDB6VhvXv3xubNm1GvXj0cPXoUw4YNyzO+i4sLcnJycPLkSbRr1y7P8MqVK+Pp06d49uyZFHaKcotwamoq4uLisHr1arRq1QoA8Ntvvym1qVevHtatW4d///03378ohg8fjrp162LFihXIzMxU+YWit3P69Gl0794dQ4YMAfBqp3X9+nU4OzurubKicXJywubNm/HixQvp7pk3L64vjg0bNuDRo0fo3bt3vm0qV64MX19f+Pr6olWrVpg0aRK+/fZbaGtrA3gVpl53+vRprFixAp07dwYA3L17FykpKcWqq169etiwYQMyMzPz/ChZWlrC1tYWN2/exODBg4s13bIo96hyYmIiGjZsCCDv/qag9VEYZ2dnZGVl4fz589LRw/j4eKVHSri6uiIpKQmampr5Hn0+ffo0fH190bNnTwCvrpW5fft2sWopjmPHjuHy5cuYOHFivm2MjY3Rv39/9O/fH3369EGnTp2kfauWlpbKbfNdl6Gwfbirqyvi4+PzDb6ljafGZGL//v149OgR/P39UbduXaVPnz598OOPPyIoKAhbt25FUFAQ4uLicPnyZSxatAjAq7sCfHx84Ofnh7179+LWrVs4ceIEduzYAQBo2rQp9PX1MW3aNNy4cQNbtmzJc0eaKqampqhUqRLWrFmDGzdu4NixYwgMDFRqM3DgQFhZWaFHjx44c+YMbt68id27d+Ps2bNSG2dnZzRr1gxffPEFBg4c+E5/DZKyGjVqICIiApGRkYiLi8Onn36KpKQkdZdVZIMGDUJOTg5GjhyJuLg46a9boOC/+AHg+fPnSEpKwr179/DHH3/giy++wKhRozB69Gh4enqqHGfWrFn45ZdfcOPGDVy5cgX79++XQqOFhQX09PRw6NAh/PPPP3jy5AmAV+t406ZNiIuLwx9//IHBgwcXexseO3Ys0tLSMGDAAJw/fx7Xr1/Hpk2bEB8fD+DVRekLFy7Ed999h2vXruHy5csICQnBkiVLijWf9+XFixdISkpS+uSGQz09PTRr1gxfffUVYmNjcerUKcyYMUNp/MLWR0Fq166NTp06YcSIEfjjjz8QHR2N4cOHK/2btGvXDs2bN0ePHj0QHh6O27dvIzIyEjNmzJCCdo0aNbBnzx7ExMTg0qVL0rZYkuvn/v37uHDhAhYsWIDu3buja9euGDp0qMpxli5dim3btuHq1au4du0adu7cCSsrK+kIVtWqVXH06FEkJSXh0aNHJbYMhe3DZ82ahY0bN2L27Nm4cuUK4uLisH379jz/pqWFQUgmfvzxR7Rr1w4mJiZ5hvXu3RsxMTEwNjbGzp07sW/fPjRo0ABt2rRRujNo5cqV6NOnD8aMGQMnJyeMGDECz549A/DqGRw//fQTwsLCpNurZ8+eXWhdFSpUwLZt2xAdHY26deti4sSJ+Oabb5TaaGtr4/Dhw7CwsEDnzp3h4uKCr776Ks8hfX9/f7x8+RJ+fn5vsYYoPzNnzoSrqys6duwIDw8PaYdWXhgbG+PXX39FTEwMGjRogOnTp2PWrFkACj/svnbtWlhbW8PR0RE9e/ZEbGwstm/fXuBt59ra2pg6dSrq1auH1q1bQ0NDA9u2bQPw6rq877//HqtXr4aNjQ26d+8O4NV1bY8ePULDhg3h7e2NcePGwcLColjLWalSJRw7dky6Q8fNzQ1r166VjoYMHz4c69atQ2hoKFxcXODu7o7Q0NB8T6Oo26FDh2Btba30+fjjj6Xh69evR2ZmJho1aoTx48dj3rx5SuMXtj4KExISAjs7O7i7u6NXr17SbfK5FAoFwsLC0Lp1a/j5+aFWrVoYMGAAbt++LV0Pt3TpUpiamqJFixbo1q0bOnbsCFdX1xJYO/+3fqpWrYpOnTrh+PHj+P777/HLL7/ke7rT0NAQX3/9NRo1aoTGjRvj9u3bCAsLk041Ll68GBEREbCzs5OOtJXEMhS2D+/YsSP279+PiIgING7cGM2aNcOSJUvg4ODwDmuo6BTiXU6WE5Uh8+fPx7Zt23D58mV1l0Jl3ObNmzFs2DA8efKERw+JZI7XCFG5l56ejri4OCxfvrzcPCKf3q+NGzeievXqsLW1xaVLl/DFF1+gX79+DEFExCBE5d/YsWOxdetW9OjRg6fFSKWkpCTMmjULSUlJsLa2Rt++fd/fw9qIqEzjqTEiIiKSLV4sTURERLLFIERERESyxSBEREREssUgRERERLLFIERElA+FQoG9e/equwwiKkUMQkRUpvn6+kKhUGDUqFF5ho0ZMwYKhQK+vr5FmtaJEyegUCiU3hlVkMTERHh5eRWjWiIqbxiEiKjMs7Ozw7Zt2/Dff/9J/TIyMrB161bY29uX+Pxy36xtZWUlvaiViD5MDEJEVOa5urrC3t4ee/bskfrt2bNH6Z1IACCEwKJFi1C9enXo6emhfv362LVrFwDg9u3b0otSTU1NlY4keXh4YOzYsQgMDIS5uTnat28PIO+psXv37mHAgAEwMzODgYEBGjVqJL2P79KlS/D09ISRkRGMjY3h5ub2Tm+5J6L3g0+WJqJyYdiwYQgJCcHgwYMBvHrppp+fH06cOCG1mTFjBvbs2YOVK1eiZs2aOHXqFIYMGYLKlSvj448/xu7du9G7d2/Ex8fD2NhY6RUbGzZswOjRo3HmzBmoes5s7ss7bW1tsW/fPlhZWeHChQvSm7gHDx6Mhg0bYuXKldDQ0EBMTEyRX/BJROrDIERE5YK3tzemTp2K27dvQ6FQ4MyZM9i2bZsUhJ49e4YlS5bg2LFjaN68OQCgevXq+O2337B69Wq4u7vDzMwMAGBhYYGKFSsqTb9GjRpYtGhRvvPfsmULHj58iKioKGk6NWrUkIYnJCRg0qRJcHJyAgDUrFmzpBadiEoRgxARlQvm5ubo0qULNmzYACEEunTpAnNzc2l4bGwsMjIypNNauV6+fKl0+iw/jRo1KnB4TEwMGjZsKIWgNwUGBmL48OHYtGkT2rVrh759+8LR0bEIS0ZE6sQgRETlhp+fH8aOHQsACA4OVhqWe4rqwIEDsLW1VRpWlAueDQwMChxe2JvqZ8+ejUGDBuHAgQM4ePAggoKCsG3bNvTs2bPQeROR+vBiaSIqNzp16oSXL1/i5cuX6Nixo9KwOnXqQEdHBwkJCahRo4bSx87ODgCgra0NAMjOzi72vOvVq4eYmBj8+++/+bapVasWJk6ciMOHD6NXr14ICQkp9nyI6P1iECKickNDQwNxcXGIi4uDhoaG0jAjIyP873//w8SJE7Fhwwb8/fffuHjxIoKDg7FhwwYAgIODAxQKBfbv34+HDx8iPT29yPMeOHAgrKys0KNHD5w5cwY3b97E7t27cfbsWfz3338YO3YsTpw4gTt37uDMmTOIioqCs7NziS4/EZU8BiEiKleMjY1hbGysctiXX36JWbNmYeHChXB2dkbHjh3x66+/olq1agAAW1tbzJkzB1OmTIGlpaV0mq0otLW1cfjwYVhYWKBz585wcXHBV199BQ0NDWhoaCA1NRVDhw5FrVq10K9fP3h5eWHOnDklssxEVHoUQtV9okREREQywCNCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkW/8P+Vd7PJQDwF0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the metrics for SVM\n",
    "svm_metrics = {\n",
    "    'Accuracy': accuracy_svm,\n",
    "    'Hamming Distance': avg_hamming_distance_svm,\n",
    "    'Euclidean Distance': avg_euclidean_distance_svm\n",
    "}\n",
    "\n",
    "# Define the metrics for Logistic Regression\n",
    "logreg_metrics = {\n",
    "    'Accuracy': accuracy_logistic_regression,\n",
    "    'Hamming Distance': avg_hamming_distance_logistic_regression,\n",
    "    'Euclidean Distance': avg_euclidean_distance_logistic_regression\n",
    "}\n",
    "\n",
    "# Create a list of metric names\n",
    "metrics = list(svm_metrics.keys())\n",
    "\n",
    "# Create a list of SVM metric values\n",
    "svm_values = list(svm_metrics.values())\n",
    "\n",
    "# Create a list of Logistic Regression metric values\n",
    "logreg_values = list(logreg_metrics.values())\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the position of the bars on the x-axis\n",
    "r1 = range(len(metrics))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(r1, svm_values, color='blue', width=bar_width, edgecolor='black', label='SVM')\n",
    "plt.bar(r2, logreg_values, color='orange', width=bar_width, edgecolor='black', label='Logistic Regression')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Metrics: SVM vs Logistic Regression')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(metrics))], metrics)\n",
    "plt.legend()\n",
    "\n",
    "# Set the y-axis scale to logarithmic\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5ff403",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "### SVM interpretation\n",
    "\n",
    "The repeated occurrence of '7' as the chosen support vector suggests that instances with this specific feature value hold significant importance in the classification task. The value '7' plays a crucial role in determining the decision boundary between the classes, indicating that instances associated with '7' have distinct characteristics that differentiate them from other data points. These instances strongly influence the SVM model's predictions and contribute significantly to the separation of the classes. Overall, the repeated appearance of '7' as support vectors indicates its relevance and influence in the classification process.\n",
    "\n",
    "### Logistic regression interpretation\n",
    "\n",
    "The weight (coefficient) for 'tribe_status' is -0.67694186. In logistic regression, the coefficients represent the impact of each feature on the predicted probability of the target variable.\n",
    "\n",
    "Since 'tribe_status' is a categorical feature, it likely represents different categories or groups within the data. In this case, the weight of -0.67694186 indicates the effect of each unit change in the 'tribe_status' feature on the log-odds of the target variable.\n",
    "\n",
    "Specifically, for each unit increase in 'tribe_status', the log-odds of the target variable decrease by approximately 0.67694186. This suggests that higher values of 'tribe_status' are associated with a lower likelihood or probability of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8288b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Support Vectors:\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[11]\n",
      "[6]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[0]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[5]\n",
      "[8]\n",
      "[10]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "Weight for 'tribe_status': [-0.64505284]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the indices of the support vectors\n",
    "support_vector_indices = svm_model.support_\n",
    "\n",
    "# Retrieve the support vectors from the training set\n",
    "support_vectors = X_train[support_vector_indices]\n",
    "\n",
    "# Print the support vectors\n",
    "print(\"Chosen Support Vectors:\")\n",
    "for vector in support_vectors:\n",
    "    print(vector)\n",
    "\n",
    "# Retrieve the learned coefficient from the logistic regression model\n",
    "coefficient = logreg_model.coef_[0]\n",
    "\n",
    "# Print the weight for the feature\n",
    "print(f\"Weight for 'tribe_status': {coefficient}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5fd1bef",
   "metadata": {},
   "source": [
    "## Simulation of survivor seasons and predicting the order in which people leave the game\n",
    "\n",
    "The simulation model employed in this code is well-suited for the given dataset, which corresponds to the TV show Survivor. In Survivor, contestants are eliminated one by one, and an obvious objective is to predict the next person who will leave the show. To ensure accurate predictions, it is crucial to consider only the remaining contestants at each stage, as those who have already been eliminated would not contribute to the decision-making process.\n",
    "\n",
    "The code implements a leave-one-group-out cross-validation technique, which aligns with the Survivor format. Each iteration of the cross-validation loop represents a new stage of the show, where a group of contestants is considered for prediction while excluding the others who have already been eliminated. This simulation approach ensures that the predictions are based on the available pool of contestants, mimicking the progression of the actual show.\n",
    "\n",
    "By training and evaluating the SVM and logistic regression models on the remaining contestants in each iteration, the simulation model captures the dynamic nature of Survivor, where the characteristics and interactions among the remaining contestants influence the prediction outcomes. The model predicts the \"orderOut\" values (the order of elimination) for the test set, and the accuracy of the predicted outcomes is calculated against the true outcomes.\n",
    "\n",
    "Overall, this simulation model ideologically aligns with Survivor by accounting for the evolving dynamics of the show, focusing on the remaining contestants, and predicting their order of elimination. It ensures that predictions are based on the relevant subset of contestants and provides a practical and effective approach for forecasting the outcomes in the context of the TV show Survivor.\n",
    "\n",
    "It is important to note that the code provided is still a work in progress and requires further refinement to ensure that the simulation model incorporates the concept of considering only the remaining contestants at each stage accurately. Currently, the simulation model in the code may not fully capture the dynamics of the Survivor show, as it does not explicitly filter out eliminated contestants from the prediction process at each iteration. Therefore, adjustments and modifications need to be made to the code to ensure that the model adheres to the elimination rules of the show. Additionally, fine-tuning the model's parameters and implementing appropriate data preprocessing techniques will be essential to improve the accuracy of the predictions. Ongoing development and iterative improvements are necessary to align the simulation model more closely with the actual progression of the Survivor TV show and provide meaningful insights into predicting the order of elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8777bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Outcomes:\n",
      "[3, 9, 5, 3, 3, 9, 5, 5, 5, 9, 5, 5, 5, 5, 9, 3, 5, 5, 5, 5, 5, 9, 9, 5, 5, 9, 3, 3, 5, 9, 9, 3, 3, 5, 5, 9, 5, 5, 5, 5, 5, 9, 5, 5, 9, 5, 9, 5, 9, 3, 9, 3, 5, 8, 8, 3, 9, 5, 3, 8, 8, 9, 5, 5, 3, 5, 1, 8, 5, 5, 9, 1, 3, 3, 8, 3, 3, 3, 3, 5, 3, 5, 8, 5, 3, 3, 8, 9, 5, 5, 9, 9, 3, 5, 9, 5, 5, 3, 3, 5, 5, 9, 5, 5, 9, 9, 3, 9, 5, 9, 9, 9, 3, 1, 3, 5, 9, 3, 5, 9, 3, 9, 5, 3, 3, 9, 9, 9, 5, 9, 9, 3, 9, 5, 3, 5, 9, 5, 9, 9, 9, 5, 9, 9, 3, 5, 9, 9, 3, 5, 3, 9, 5, 9, 3, 9, 5, 5, 1, 9, 9, 9, 5, 9, 5, 9, 9, 5, 9, 3, 5, 9, 9, 9, 3, 3, 3, 3, 3, 8, 9, 5, 5, 9, 5, 5, 9, 3, 9, 8, 9, 8, 9, 9, 5, 9, 5, 9, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 3, 5, 3, 3, 9, 5, 3, 5, 9, 8, 5, 9, 3, 5, 9, 5, 5, 5, 5, 9, 5, 5, 5, 9, 5, 5, 5, 9, 5, 9, 3, 5, 5, 9, 9, 9, 9, 9, 9, 3, 5, 5, 9, 5, 9, 3, 5, 9, 9, 3, 5, 9, 5, 5, 3, 3, 5, 5, 9, 5, 5, 5, 5, 9, 5, 5, 9, 5, 9, 9, 3, 9, 9, 5, 9, 5, 1, 3, 5, 5, 9, 5, 1, 5, 5, 9, 9, 5, 1, 5, 5, 3, 5, 9, 5, 5, 3, 5, 5, 9, 5, 5, 5, 9, 5, 5, 9, 5, 5, 9, 3, 9, 1, 9, 3, 5, 9, 5, 3, 5, 5, 9, 9, 9, 9, 5, 5, 5, 5, 5, 3, 5, 9, 5, 5, 5, 9, 5, 9, 5, 9, 9, 9, 9, 9, 9, 5, 9, 9, 5, 5, 9, 5, 5, 9, 9, 3, 5, 5, 5, 8, 9, 8, 3, 9, 5, 9, 3, 9, 3, 9, 9, 3, 9, 3, 3, 5, 5, 5, 5, 9, 5, 5, 9, 5, 9, 9, 16, 5, 9, 3, 9, 3, 5, 5, 9, 9, 9, 5, 5, 5, 3, 5, 9, 5, 9, 3, 5, 3, 3, 5, 5, 5, 5, 5, 3, 5, 3, 3, 9, 3, 5, 3, 3, 9, 5, 5, 5, 5, 9, 9, 5, 9, 5, 3, 3, 5, 9, 9, 5, 5, 9, 5, 5, 5, 5, 5, 5, 3, 9, 3, 3, 3, 9, 5, 3, 5, 9, 1, 5, 3, 5, 9, 9, 5, 5, 3, 5, 9, 5, 5, 5, 3, 9, 5, 1, 5, 5, 9, 9, 9, 5, 5, 9, 5, 5, 3, 5, 3, 16, 5, 5, 3, 3, 5, 5, 9, 9, 3, 9, 5, 3, 9, 5, 5, 5, 5, 5, 9, 5, 9, 9, 3, 5, 9, 1, 9, 9, 9, 5, 5, 3, 1, 9, 5, 3, 9, 5, 5, 5, 3, 5, 9, 5, 5, 9, 9, 5, 5, 3, 9, 5, 5, 1, 3, 5, 5, 5, 5, 3, 5, 9, 5, 5, 5, 3, 9, 9, 3, 5, 5, 5, 3, 9, 5, 3, 9, 3, 5, 5, 5, 3, 9, 9, 9, 3, 5, 5, 3, 9, 5, 5, 9, 3, 9, 5, 5, 9, 9, 5, 5, 3, 5, 5, 9, 5, 5, 9, 5, 5, 3, 3, 5, 9, 9, 5, 9, 5, 5, 5, 5, 5, 9, 3, 5, 3, 9, 3, 5, 9, 9, 9, 5, 5, 9, 5, 5, 5, 5, 9, 5, 5, 5, 9, 5, 3, 9, 9, 3, 3, 3, 3, 9, 5, 5, 5, 8, 5, 5, 9, 9, 5, 5, 5, 3, 5, 5, 5, 5, 5, 9, 5, 5, 3, 5, 5, 5, 5, 5, 3, 3, 5, 9, 3, 3, 5, 5, 5, 5, 5, 5, 3, 9, 9, 5, 5, 5, 5, 3, 3, 5, 9, 5, 1, 9, 5, 5, 9, 5, 9, 5, 3, 5, 5, 9, 9, 5, 5, 5, 3, 9, 3, 5, 9, 9, 9, 5, 5, 5, 5, 5, 3, 9, 9, 9, 5, 9, 3, 5, 2, 3, 3, 5, 1, 3, 5, 3, 5, 5, 5, 5, 3, 3, 3, 5, 5, 5, 9, 5, 9, 3, 5, 5, 9, 5, 9, 9, 3, 3, 3, 5, 5, 5, 5, 5, 3, 9, 5, 9, 3, 3, 5, 5, 5, 5, 5, 9, 1, 5, 5, 9, 5, 3, 5, 5, 9, 5, 5, 3, 9, 5, 1, 5, 9, 9, 5, 5, 3, 5, 3, 5, 5, 5, 9, 5, 5, 5, 5, 3, 9, 5, 5, 5, 3, 3, 5, 3, 5, 9, 5, 3, 3, 3, 9, 5, 5, 5, 5, 5, 9, 5, 9, 3, 3, 5, 5, 5, 5, 5, 5, 3, 3, 5, 3, 8, 3, 5, 9, 5, 8, 3, 3, 5, 3, 9, 9, 3, 3, 5, 5, 5, 5, 3, 3, 3, 9, 3, 5, 5, 9, 3, 5, 5, 5, 5, 9, 9, 5, 9, 3, 5, 1, 5, 9, 5, 9, 9, 5, 5, 3, 9, 9, 9, 5, 9, 5, 5, 5, 3, 3, 5, 5, 9, 9, 3, 5, 9, 5, 3, 5, 5, 5, 9, 9, 3, 5, 5, 1, 3, 9, 9, 9, 9, 3, 9, 3, 9, 3, 3, 9, 5, 9, 5, 9, 3, 3, 9, 5, 9, 9, 5, 9, 5, 5, 5, 5, 9, 9, 5, 3, 9, 5, 9, 2, 5, 3, 5, 5, 9, 9, 3, 3, 9, 5, 5, 5, 5, 9, 9, 5, 5, 3, 5, 3, 3, 5, 9, 5, 5, 3, 5, 5, 9, 1, 3, 5, 9, 3, 5, 5, 5, 5, 3, 5, 3, 3, 3, 9, 3, 5, 5, 9, 5, 5, 5, 5, 5, 5, 9, 9, 5, 3, 5, 5, 3, 9, 5, 5, 5, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 9, 9, 1, 5, 9, 5, 5, 3, 9, 9, 9, 5, 5, 1, 5, 9, 9, 5, 9, 5, 3, 5, 3, 5, 5, 9, 9, 5, 5, 9, 5, 3, 9, 9, 3, 9, 5, 5, 9, 3, 5, 5, 9, 5, 5, 5, 3, 9, 5, 5, 9, 9, 5, 5, 9, 3, 3, 3, 5, 9, 5, 5, 9, 1, 3, 3, 9, 3, 9, 3, 3, 9, 5, 9, 5, 9, 1, 5, 3, 9, 9, 5, 9, 3, 3, 5, 9, 3, 5, 3, 5, 3, 9, 5, 9, 5, 9, 8, 3, 5, 5, 8, 3, 5, 3, 3, 5, 9, 5, 5, 3, 5, 5, 9, 9, 9, 5, 9, 3, 5, 5, 5, 3, 1, 9, 9, 5, 5, 9, 5, 5, 5, 9, 5, 9, 5, 5, 3]\n",
      "Accuracy: 0.06492411467116357\n"
     ]
    }
   ],
   "source": [
    "def split_dataframe(df, column_name):\n",
    "    groups = df.groupby(column_name)\n",
    "    result = [group for _, group in groups]\n",
    "    return result\n",
    "\n",
    "# Call split_dataframe on column name \"version_season\"\n",
    "season_split = split_dataframe(castawayAll, 'version_season')\n",
    "\n",
    "for df in season_split:\n",
    "    df['orderOut'] = range(1, len(df) + 1)\n",
    "\n",
    "# Perform leave-one-group-out cross-validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize a list to store the predicted outcomes\n",
    "predicted_outcomes = []\n",
    "\n",
    "# Create a list to store the true outcomes\n",
    "true_outcomes = []\n",
    "\n",
    "# Create a list of group labels corresponding to each DataFrame in season_split\n",
    "group_labels = [i for i, _ in enumerate(season_split)]\n",
    "\n",
    "# Initialize the SVM model\n",
    "model = svm.SVC()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Initialize the SVM model for each iteration\n",
    "    model = svm.SVC()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Iterate through each test DataFrame\n",
    "    for i, test_df in enumerate(test_set):\n",
    "        X_train = pd.concat(train_set)[['age', 'genderNumber']]\n",
    "        y_train = pd.concat(train_set)['orderOut']\n",
    "\n",
    "        # Fit the SVM model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the orderOut values for the test set\n",
    "        X_test = test_df[['age', 'genderNumber']]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save the predicted outcomes to the list\n",
    "        predicted_outcomes.extend(y_pred)\n",
    "\n",
    "        # Save the true outcomes to the list\n",
    "        true_outcomes.extend(test_df['orderOut'])\n",
    "\n",
    "        # Remove the row with the lowest orderOut value from the possible choices\n",
    "        min_orderOut = min(test_df['orderOut'])\n",
    "        test_set[i] = test_df[test_df['orderOut'] > min_orderOut]\n",
    "\n",
    "# Print the predicted outcomes\n",
    "print(\"Predicted Outcomes:\")\n",
    "print(predicted_outcomes)\n",
    "\n",
    "# Calculate the accuracy of the predicted outcomes\n",
    "accuracy = accuracy_score(true_outcomes, predicted_outcomes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "379e46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Outcomes:\n",
      "[3, 2, 9, 3, 3, 2, 9, 8, 9, 9, 8, 9, 8, 9, 2, 3, 8, 8, 9, 9, 8, 2, 3, 8, 8, 16, 1, 3, 8, 8, 16, 1, 3, 9, 9, 8, 9, 8, 9, 8, 8, 9, 8, 9, 2, 9, 8, 9, 16, 3, 16, 3, 8, 8, 2, 1, 16, 8, 1, 2, 16, 2, 9, 9, 16, 9, 16, 2, 8, 8, 16, 2, 3, 1, 8, 1, 1, 3, 3, 8, 1, 8, 8, 8, 3, 3, 9, 16, 9, 8, 16, 16, 1, 8, 9, 9, 9, 1, 3, 9, 8, 2, 9, 8, 2, 9, 3, 8, 8, 9, 9, 9, 3, 16, 1, 8, 9, 3, 8, 8, 2, 16, 8, 1, 3, 16, 9, 16, 9, 8, 2, 1, 9, 8, 16, 5, 8, 9, 2, 9, 9, 8, 2, 1, 1, 8, 9, 8, 3, 8, 1, 8, 9, 16, 1, 8, 8, 8, 16, 9, 9, 8, 9, 8, 9, 2, 8, 9, 2, 3, 9, 2, 9, 8, 1, 3, 1, 1, 16, 8, 2, 8, 9, 1, 8, 9, 16, 3, 9, 8, 16, 8, 16, 2, 8, 9, 8, 9, 3, 9, 8, 8, 8, 3, 8, 8, 8, 8, 9, 9, 16, 9, 8, 8, 3, 9, 3, 1, 9, 9, 3, 9, 2, 8, 9, 2, 3, 8, 9, 8, 8, 9, 9, 9, 8, 8, 8, 1, 9, 8, 9, 9, 8, 9, 3, 9, 8, 8, 16, 8, 16, 1, 2, 3, 9, 8, 16, 8, 16, 1, 8, 9, 16, 3, 9, 9, 8, 9, 1, 1, 9, 8, 16, 8, 8, 9, 8, 1, 8, 9, 16, 9, 9, 16, 1, 9, 6, 8, 9, 8, 1, 1, 9, 8, 9, 8, 1, 9, 8, 9, 2, 8, 16, 9, 9, 3, 9, 2, 9, 9, 3, 8, 9, 2, 9, 9, 8, 16, 8, 8, 1, 9, 8, 16, 1, 2, 16, 2, 3, 8, 2, 9, 1, 9, 9, 2, 9, 2, 9, 9, 8, 9, 9, 8, 1, 9, 2, 9, 9, 8, 9, 9, 1, 8, 9, 1, 1, 16, 9, 2, 8, 1, 1, 9, 9, 9, 9, 8, 9, 9, 1, 9, 9, 2, 2, 1, 2, 1, 9, 2, 2, 3, 9, 1, 16, 2, 3, 9, 3, 3, 8, 2, 9, 9, 2, 9, 8, 9, 8, 9, 2, 3, 8, 16, 1, 9, 1, 9, 8, 16, 16, 8, 8, 9, 8, 3, 8, 16, 9, 1, 1, 8, 3, 1, 9, 8, 9, 8, 9, 3, 8, 1, 3, 16, 1, 9, 3, 1, 9, 8, 9, 8, 9, 9, 2, 8, 9, 9, 3, 1, 8, 2, 16, 8, 9, 1, 8, 9, 8, 8, 9, 8, 3, 16, 1, 1, 3, 16, 9, 1, 9, 8, 1, 8, 3, 9, 1, 9, 8, 8, 3, 9, 9, 5, 8, 9, 1, 9, 8, 2, 9, 9, 16, 9, 16, 8, 8, 9, 8, 9, 1, 8, 1, 3, 8, 9, 3, 1, 9, 9, 2, 16, 1, 2, 2, 3, 16, 8, 9, 8, 9, 8, 9, 8, 9, 9, 1, 9, 16, 16, 16, 2, 2, 8, 5, 1, 1, 9, 9, 1, 2, 8, 9, 8, 3, 8, 16, 9, 9, 9, 2, 8, 9, 1, 2, 9, 8, 3, 3, 8, 8, 8, 9, 1, 9, 2, 9, 9, 9, 3, 9, 2, 1, 9, 8, 8, 1, 2, 8, 1, 9, 3, 9, 9, 8, 3, 8, 9, 2, 3, 8, 9, 3, 16, 8, 9, 2, 16, 2, 8, 9, 2, 1, 9, 8, 3, 8, 9, 8, 8, 9, 9, 8, 8, 1, 3, 8, 2, 9, 9, 2, 8, 9, 9, 9, 8, 9, 3, 9, 1, 9, 3, 8, 2, 16, 9, 8, 8, 16, 9, 9, 9, 8, 1, 8, 8, 9, 9, 8, 3, 16, 9, 3, 3, 1, 1, 2, 8, 9, 9, 9, 8, 9, 8, 2, 8, 8, 8, 1, 8, 8, 9, 8, 9, 9, 9, 9, 3, 8, 8, 9, 9, 8, 1, 3, 8, 8, 3, 1, 9, 8, 9, 9, 9, 8, 1, 16, 2, 8, 9, 9, 8, 3, 1, 9, 2, 8, 3, 2, 9, 8, 1, 9, 16, 8, 1, 9, 9, 9, 16, 8, 8, 8, 3, 1, 3, 9, 9, 9, 16, 8, 9, 8, 8, 8, 3, 16, 1, 16, 8, 2, 1, 9, 3, 3, 3, 8, 2, 2, 8, 3, 8, 8, 8, 9, 1, 3, 1, 9, 9, 9, 1, 9, 16, 1, 8, 8, 1, 9, 9, 9, 1, 3, 3, 8, 9, 8, 8, 8, 3, 16, 8, 2, 3, 1, 8, 8, 9, 9, 9, 16, 2, 8, 9, 2, 5, 3, 9, 9, 16, 8, 8, 1, 16, 9, 1, 5, 16, 9, 9, 9, 3, 8, 3, 8, 8, 8, 2, 8, 9, 8, 8, 3, 8, 8, 8, 8, 3, 3, 9, 3, 9, 8, 9, 1, 3, 1, 1, 8, 8, 9, 8, 9, 16, 8, 8, 3, 3, 9, 9, 8, 8, 9, 9, 1, 1, 9, 2, 8, 3, 8, 2, 9, 9, 3, 2, 8, 2, 9, 9, 1, 2, 9, 8, 9, 8, 1, 3, 2, 9, 3, 9, 9, 8, 3, 8, 5, 8, 5, 16, 16, 9, 2, 3, 9, 1, 9, 16, 8, 2, 16, 9, 8, 3, 2, 16, 16, 9, 9, 9, 9, 8, 3, 1, 8, 8, 2, 9, 1, 8, 16, 9, 1, 8, 9, 5, 2, 9, 3, 8, 9, 16, 1, 16, 16, 2, 2, 3, 8, 3, 9, 1, 3, 2, 8, 16, 9, 2, 1, 3, 8, 9, 1, 3, 9, 1, 8, 9, 8, 8, 16, 16, 9, 1, 16, 8, 9, 3, 8, 3, 8, 8, 2, 8, 3, 1, 2, 8, 8, 8, 9, 16, 2, 9, 5, 1, 9, 3, 3, 8, 9, 9, 8, 3, 9, 9, 9, 1, 3, 8, 16, 1, 9, 2, 8, 8, 1, 2, 3, 3, 3, 2, 1, 8, 9, 9, 8, 8, 8, 8, 9, 9, 9, 2, 8, 3, 9, 9, 1, 9, 8, 9, 8, 16, 2, 9, 9, 9, 8, 8, 8, 5, 8, 8, 9, 9, 1, 8, 16, 9, 16, 5, 16, 8, 8, 1, 1, 2, 16, 9, 9, 16, 8, 9, 9, 8, 8, 8, 3, 9, 1, 9, 9, 9, 2, 8, 9, 9, 8, 3, 2, 16, 3, 2, 8, 8, 9, 1, 9, 9, 16, 8, 9, 8, 3, 9, 9, 8, 16, 16, 5, 8, 2, 2, 3, 3, 8, 2, 9, 9, 2, 1, 1, 3, 16, 3, 2, 1, 3, 16, 9, 16, 8, 2, 3, 9, 1, 16, 2, 8, 2, 3, 3, 8, 16, 3, 9, 1, 8, 1, 16, 8, 1, 8, 16, 9, 1, 9, 9, 8, 3, 9, 1, 1, 8, 9, 8, 8, 3, 8, 9, 2, 9, 8, 9, 16, 3, 8, 8, 8, 1, 1, 16, 8, 9, 8, 16, 9, 8, 5, 16, 8, 9, 9, 8, 3]\n",
      "Accuracy: 0.05986509274873524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the predicted outcomes\n",
    "predicted_outcomes = []\n",
    "\n",
    "# Create a list to store the true outcomes\n",
    "true_outcomes = []\n",
    "\n",
    "# Create a list of group labels corresponding to each DataFrame in season_split\n",
    "group_labels = [i for i, _ in enumerate(season_split)]\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Initialize the SVM model for each iteration\n",
    "    model = LogisticRegression()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Iterate through each test DataFrame\n",
    "    for i, test_df in enumerate(test_set):\n",
    "        X_train = pd.concat(train_set)[['age', 'genderNumber']]\n",
    "        y_train = pd.concat(train_set)['orderOut']\n",
    "\n",
    "        # Fit the SVM model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the orderOut values for the test set\n",
    "        X_test = test_df[['age', 'genderNumber']]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save the predicted outcomes to the list\n",
    "        predicted_outcomes.extend(y_pred)\n",
    "\n",
    "        # Save the true outcomes to the list\n",
    "        true_outcomes.extend(test_df['orderOut'])\n",
    "\n",
    "        # Remove the row with the lowest orderOut value from the possible choices\n",
    "        min_orderOut = min(test_df['orderOut'])\n",
    "        test_set[i] = test_df[test_df['orderOut'] > min_orderOut]\n",
    "\n",
    "# Print the predicted outcomes\n",
    "print(\"Predicted Outcomes:\")\n",
    "print(predicted_outcomes)\n",
    "\n",
    "# Calculate the accuracy of the predicted outcomes\n",
    "accuracy = accuracy_score(true_outcomes, predicted_outcomes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
