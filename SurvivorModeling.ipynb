{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6dfc62e",
   "metadata": {},
   "source": [
    "## Survivor Data Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee31e08",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639ee194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the path to the survivorData directory\n",
    "data_dir = os.path.join(current_dir, '..', 'survivorData')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c4d6aa8",
   "metadata": {},
   "source": [
    "### Read in csv files as Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e239ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file names\n",
    "csv_files = [\n",
    "    'advantage_movement.csv',\n",
    "    'boot_mapping.csv',\n",
    "    'castaways.csv',\n",
    "    'castaway_details.csv',\n",
    "    'challenge_description.csv',\n",
    "    'challenge_results.csv',\n",
    "    'confessionals.csv',\n",
    "    'jury_votes.csv',\n",
    "    'screen_time.csv',\n",
    "    'season_palettes.csv',\n",
    "    'season_summary.csv',\n",
    "    'survivor_auction.csv',\n",
    "    'tribe_colours.csv',\n",
    "    'tribe_mapping.csv',\n",
    "    'viewers.csv',\n",
    "    'vote_history.csv'\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each CSV file and read its data into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    # Specify the relative path to the CSV file\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "    \n",
    "    # Read the data from the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[csv_file] = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c5e475b",
   "metadata": {},
   "source": [
    "### Clean up the data and feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4624e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tribe_status column to category type\n",
    "dataframes['tribe_colours.csv']['tribe_status'] = dataframes['tribe_colours.csv']['tribe_status'].astype('category')\n",
    "\n",
    "# Convert result to a categorical variable\n",
    "dataframes['castaways.csv']['result'] = pd.Categorical(dataframes['castaways.csv']['result'])\n",
    "dataframes['castaways.csv']['result'] = dataframes['castaways.csv']['result'].cat.codes\n",
    "\n",
    "# Merge challenge_results and castaway_details dataframes on castaway_id\n",
    "castawayAll = pd.merge(dataframes['castaways.csv'], dataframes['castaway_details.csv'], on='castaway_id', how =\"left\")\n",
    "\n",
    "castawayAll['genderNumber'] = np.where(castawayAll['gender'] == 'Male', 1,\n",
    "                                     np.where(castawayAll['gender'] == 'Female', 2,\n",
    "                                              np.where(castawayAll['gender'] == 'Non-binary', 3, 0)))\n",
    "castawayAll['won'] = np.where(castawayAll['result'] == 'Sole Survivor', 1, 0)\n",
    "\n",
    "castawayAll = castawayAll.dropna(subset=['age'])\n",
    "\n",
    "# Drop rows where 'season' is equal to 44\n",
    "castawayAll = castawayAll[castawayAll['season'] != 44]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a0a73ac",
   "metadata": {},
   "source": [
    "## Predicting Color Values in the survivor dataset: A Comparative Analysis of SVM and Logistic Regression Models\n",
    "\n",
    "### Introduction:\n",
    "In this overview, we will delve into the rationale behind predicting color values in a dataset and explore the unique situation it presents when it comes to quantifying results. Specifically, we will compare the performance of Support Vector Machine (SVM) and Logistic Regression models in predicting color values and evaluate the effectiveness of various metrics such as average accuracy, Hamming distance, and Euclidean distance.\n",
    "\n",
    "### Predicting Color Values in a Dataset:\n",
    "Color is an essential aspect of visual data analysis and has a wide range of applications, including image processing, computer vision, and data visualization. By predicting color values in a dataset, we can gain insights into patterns, trends, and relationships that are not immediately apparent to the human eye. This predictive modeling approach allows us to develope skills to uncover hidden information and make data-driven decisions.\n",
    "\n",
    "### Comparison of SVM and Logistic Regression Models:\n",
    "To determine the best approach for predicting color values, we have chosen to compare the performance of two popular machine learning algorithms: Support Vector Machine (SVM) and Logistic Regression. Both models are widely used in classification tasks and have demonstrated success in various domains.\n",
    "\n",
    "1. Support Vector Machine (SVM):\n",
    "SVM is a powerful algorithm that aims to find an optimal hyperplane in a high-dimensional feature space. It separates data points into distinct classes by maximizing the margin between them. SVM is known for its ability to handle complex datasets and nonlinear relationships effectively. Its versatility and robustness make it a suitable candidate for predicting color values in a dataset.\n",
    "\n",
    "2. Logistic Regression:\n",
    "Logistic Regression is a probabilistic machine learning algorithm used for binary classification tasks. It models the relationship between the input features and the probability of a particular outcome. Logistic Regression is known for its simplicity, interpretability, and efficiency. While it may not capture complex nonlinear relationships as effectively as SVM, it can still yield accurate predictions in certain scenarios.\n",
    "\n",
    "### Quantifying Results:\n",
    "To evaluate the performance of our SVM and Logistic Regression models in predicting color values, we will utilize several metrics that address different aspects of model performance:\n",
    "\n",
    "1. Average Accuracy:\n",
    "Average accuracy measures the percentage of correctly classified instances across all classes.\n",
    "\n",
    "2. Hamming Distance:\n",
    "Hamming distance quantifies the dissimilarity between two color values by measuring the number of positions at which they differ. Since color values can be represented as vectors in a multi-dimensional space, Hamming distance provides a useful metric for evaluating the similarity or dissimilarity of predicted colors.\n",
    "\n",
    "3. Euclidean Distance:\n",
    "Euclidean distance measures the straight-line distance between two points in a multi-dimensional space. In the context of color values, Euclidean distance allows us to determine the proximity of predicted colors to the ground truth. \n",
    "\n",
    "### Conclusion:\n",
    "Predicting color values in a dataset presents a unique situation due to its visual and perceptual nature. By comparing the performance of SVM and Logistic Regression models, we can gain insights into the effectiveness of these algorithms in accurately predicting color values. Furthermore, by utilizing metrics such as average accuracy, Hamming distance, and Euclidean distance, we can comprehensively evaluate the performance of the models and make informed decisions regarding their suitability for color prediction tasks.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3d4b4e",
   "metadata": {},
   "source": [
    "## Color prediction with SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa1c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08695652173913043\n",
      "Average Hamming Distance for Incorrect Predictions: 4.456521739130435\n",
      "Average Euclidean Distance for All Predictions: 237.12137264562665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:202: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  return array[key] if axis == 0 else array[:, key]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training\n",
    "X = dataframes['tribe_colours.csv']['tribe_status'].values.reshape(-1, 1)\n",
    "y = dataframes['tribe_colours.csv']['tribe_colour']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "\n",
    "# Calculate Hamming distance for all predictions\n",
    "hamming_distances = []\n",
    "\n",
    "for idx in range(len(y_pred)):\n",
    "    hamming_dist = sum(el1 != el2 for el1, el2 in zip(y_pred[idx], y_test.iloc[idx]))\n",
    "    hamming_distances.append(hamming_dist)\n",
    "\n",
    "# Calculate average Hamming distance for incorrect predictions\n",
    "avg_hamming_distance_svm = np.mean(hamming_distances)\n",
    "\n",
    "# The Hamming distance measures the dissimilarity between two strings of equal length. In the context of hex color values, \n",
    "# each character represents a component of the color (e.g., red, green, and blue), and the Hamming distance calculates \n",
    "# the number of positions at which the predicted and actual color values differ.\n",
    "\n",
    "# Since hex color values consist of six characters (e.g., #RRGGBB), the Hamming distance for hex color values can range from 0 to 6.\n",
    "\n",
    "# Print average Hamming distance for incorrect predictions\n",
    "print(\"Average Hamming Distance for Incorrect Predictions:\", avg_hamming_distance_svm)\n",
    "\n",
    "# Calculate Euclidean distance for color similarity\n",
    "euclidean_distances = []\n",
    "for idx in range(len(y_pred)):\n",
    "    predicted_color = y_pred[idx][1:]  # Remove the \"#\" character from the predicted color\n",
    "    actual_color = y_test.iloc[idx][1:]  # Remove the \"#\" character from the actual color\n",
    "    \n",
    "    # Convert hex color values to RGB tuples\n",
    "    predicted_rgb = tuple(int(predicted_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    actual_rgb = tuple(int(actual_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    \n",
    "    # Calculate Euclidean distance between RGB tuples\n",
    "    distance = math.sqrt(sum((p - a) ** 2 for p, a in zip(predicted_rgb, actual_rgb)))\n",
    "    euclidean_distances.append(distance)\n",
    "\n",
    "# Calculate average Euclidean distance for all predictions\n",
    "avg_euclidean_distance_svm = np.mean(euclidean_distances)\n",
    "\n",
    "# The Euclidean distance measures the spatial or geometric distance between two colors in the RGB color space.\n",
    "# In the RGB color space, each color is represented by three components: red (R), green (G), and blue (B). \n",
    "# The Euclidean distance calculates the straight-line distance between two colors in this three-dimensional space.\n",
    "\n",
    "# Print average Euclidean distance for all predictions\n",
    "print(\"Average Euclidean Distance for All Predictions:\", avg_euclidean_distance_svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59301fe6",
   "metadata": {},
   "source": [
    "## Color prediction with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e1402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.021739130434782608\n",
      "Average Hamming Distance for Incorrect Predictions: 4.8478260869565215\n",
      "Average Euclidean Distance for All Predictions: 255.49542112683773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_logistic_regression = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_logistic_regression)\n",
    "\n",
    "# Calculate Hamming distance for all predictions\n",
    "hamming_distances = []\n",
    "\n",
    "for idx in range(len(y_pred)):\n",
    "    hamming_dist = sum(el1 != el2 for el1, el2 in zip(y_pred[idx], y_test.iloc[idx]))\n",
    "    hamming_distances.append(hamming_dist)\n",
    "\n",
    "# Calculate average Hamming distance for incorrect predictions\n",
    "avg_hamming_distance_logistic_regression = np.mean(hamming_distances)\n",
    "\n",
    "# The Hamming distance measures the dissimilarity between two strings of equal length. In the context of hex color values, \n",
    "# each character represents a component of the color (e.g., red, green, and blue), and the Hamming distance calculates \n",
    "# the number of positions at which the predicted and actual color values differ.\n",
    "\n",
    "# Since hex color values consist of six characters (e.g., #RRGGBB), the Hamming distance for hex color values can range from 0 to 6.\n",
    "\n",
    "# Print average Hamming distance for incorrect predictions\n",
    "print(\"Average Hamming Distance for Incorrect Predictions:\", avg_hamming_distance_logistic_regression)\n",
    "\n",
    "# Calculate Euclidean distance for color similarity\n",
    "euclidean_distances = []\n",
    "for idx in range(len(y_pred)):\n",
    "    predicted_color = y_pred[idx][1:]  # Remove the \"#\" character from the predicted color\n",
    "    actual_color = y_test.iloc[idx][1:]  # Remove the \"#\" character from the actual color\n",
    "    \n",
    "    # Convert hex color values to RGB tuples\n",
    "    predicted_rgb = tuple(int(predicted_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    actual_rgb = tuple(int(actual_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    \n",
    "    # Calculate Euclidean distance between RGB tuples\n",
    "    distance = math.sqrt(sum((p - a) ** 2 for p, a in zip(predicted_rgb, actual_rgb)))\n",
    "    euclidean_distances.append(distance)\n",
    "\n",
    "# Calculate average Euclidean distance for all predictions\n",
    "avg_euclidean_distance_logistic_regression = np.mean(euclidean_distances)\n",
    "\n",
    "# The Euclidean distance measures the spatial or geometric distance between two colors in the RGB color space.\n",
    "# In the RGB color space, each color is represented by three components: red (R), green (G), and blue (B). \n",
    "# The Euclidean distance calculates the straight-line distance between two colors in this three-dimensional space.\n",
    "\n",
    "# Print average Euclidean distance for all predictions\n",
    "print(\"Average Euclidean Distance for All Predictions:\", avg_euclidean_distance_logistic_regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "988ba08a",
   "metadata": {},
   "source": [
    "## Color prediction model comparision\n",
    "\n",
    "Upon examining the graph plotted on a logarithmic scale, which enhances the visual representation of metric differences, a notable observation arises: the accuracy of the SVM model surpasses that of the Logistic Regression model by a significant margin. However, when considering the average Hamming distance and average Euclidean distance metrics, the difference between the two models is negligible.\n",
    "\n",
    "This log scale representation allows for a clearer visualization of the relative differences between the metrics. It accentuates the disparity in accuracy between SVM and Logistic Regression, emphasizing the stronger performance of SVM in terms of overall correct predictions. At the same time, the log scale helps highlight the close proximity of the two models in terms of the average Hamming distance and average Euclidean distance, indicating similar abilities to capture the patterns and relationships within the data.\n",
    "\n",
    "Therefore, taking into account the log scale representation, the graph reaffirms that SVM excels in accuracy compared to Logistic Regression, while both models demonstrate comparable results in terms of capturing the similarity between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4216337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the metrics for SVM\n",
    "svm_metrics = {\n",
    "    'Accuracy': accuracy_svm,\n",
    "    'Hamming Distance': avg_hamming_distance_svm,\n",
    "    'Euclidean Distance': avg_euclidean_distance_svm\n",
    "}\n",
    "\n",
    "# Define the metrics for Logistic Regression\n",
    "logreg_metrics = {\n",
    "    'Accuracy': accuracy_logistic_regression,\n",
    "    'Hamming Distance': avg_hamming_distance_logistic_regression,\n",
    "    'Euclidean Distance': avg_euclidean_distance_logistic_regression\n",
    "}\n",
    "\n",
    "# Create a list of metric names\n",
    "metrics = list(svm_metrics.keys())\n",
    "\n",
    "# Create a list of SVM metric values\n",
    "svm_values = list(svm_metrics.values())\n",
    "\n",
    "# Create a list of Logistic Regression metric values\n",
    "logreg_values = list(logreg_metrics.values())\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the position of the bars on the x-axis\n",
    "r1 = range(len(metrics))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(r1, svm_values, color='blue', width=bar_width, edgecolor='black', label='SVM')\n",
    "plt.bar(r2, logreg_values, color='orange', width=bar_width, edgecolor='black', label='Logistic Regression')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Metrics: SVM vs Logistic Regression')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(metrics))], metrics)\n",
    "plt.legend()\n",
    "\n",
    "# Set the y-axis scale to logarithmic\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5ff403",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "### SVM interpretation\n",
    "\n",
    "The repeated occurrence of '7' as the chosen support vector suggests that instances with this specific feature value hold significant importance in the classification task. The value '7' plays a crucial role in determining the decision boundary between the classes, indicating that instances associated with '7' have distinct characteristics that differentiate them from other data points. These instances strongly influence the SVM model's predictions and contribute significantly to the separation of the classes. Overall, the repeated appearance of '7' as support vectors indicates its relevance and influence in the classification process.\n",
    "\n",
    "### Logistic regression interpretation\n",
    "\n",
    "The weight (coefficient) for 'tribe_status' is -0.67694186. In logistic regression, the coefficients represent the impact of each feature on the predicted probability of the target variable.\n",
    "\n",
    "Since 'tribe_status' is a categorical feature, it likely represents different categories or groups within the data. In this case, the weight of -0.67694186 indicates the effect of each unit change in the 'tribe_status' feature on the log-odds of the target variable.\n",
    "\n",
    "Specifically, for each unit increase in 'tribe_status', the log-odds of the target variable decrease by approximately 0.67694186. This suggests that higher values of 'tribe_status' are associated with a lower likelihood or probability of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8288b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Support Vectors:\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[7]\n",
      "[11]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[0]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[5]\n",
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[3]\n",
      "[9]\n",
      "[10]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[11]\n",
      "[7]\n",
      "[11]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[6]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[6]\n",
      "[7]\n",
      "Weight for 'tribe_status': [-0.66052373]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the indices of the support vectors\n",
    "support_vector_indices = svm_model.support_\n",
    "\n",
    "# Retrieve the support vectors from the training set\n",
    "support_vectors = X_train[support_vector_indices]\n",
    "\n",
    "# Print the support vectors\n",
    "print(\"Chosen Support Vectors:\")\n",
    "for vector in support_vectors:\n",
    "    print(vector)\n",
    "\n",
    "# Retrieve the learned coefficient from the logistic regression model\n",
    "coefficient = logreg_model.coef_[0]\n",
    "\n",
    "# Print the weight for the feature\n",
    "print(f\"Weight for 'tribe_status': {coefficient}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5fd1bef",
   "metadata": {},
   "source": [
    "## Simulation of survivor seasons and predicting the order in which people leave the game\n",
    "\n",
    "The simulation model employed in this code is well-suited for the given dataset, which corresponds to the TV show Survivor. In Survivor, contestants are eliminated one by one, and an obvious objective is to predict the next person who will leave the show. To ensure accurate predictions, it is crucial to consider only the remaining contestants at each stage, as those who have already been eliminated would not contribute to the decision-making process.\n",
    "\n",
    "The code implements a leave-one-group-out cross-validation technique, which aligns with the Survivor format. Each iteration of the cross-validation loop represents a new stage of the show, where a group of contestants is considered for prediction while excluding the others who have already been eliminated. This simulation approach ensures that the predictions are based on the available pool of contestants, mimicking the progression of the actual show.\n",
    "\n",
    "By training and evaluating the SVM and logistic regression models on the remaining contestants in each iteration, the simulation model captures the dynamic nature of Survivor, where the characteristics and interactions among the remaining contestants influence the prediction outcomes. The model predicts the \"orderOut\" values (the order of elimination) for the test set, and the accuracy of the predicted outcomes is calculated against the true outcomes.\n",
    "\n",
    "Overall, this simulation model ideologically aligns with Survivor by accounting for the evolving dynamics of the show, focusing on the remaining contestants, and predicting their order of elimination. It ensures that predictions are based on the relevant subset of contestants and provides a practical and effective approach for forecasting the outcomes in the context of the TV show Survivor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "050afd9d",
   "metadata": {},
   "source": [
    "## Status of capabilities\n",
    "\n",
    "The provided code is still a work in progress and requires further refinement to ensure accurate incorporation of the concept of considering only the remaining contestants at each stage. Adjustments and modifications are needed to improve the code's adherence to the elimination rules of the Survivor show.\n",
    "\n",
    "Additionally, fine-tuning the model's parameters and implementing appropriate data preprocessing techniques are essential steps to enhance the accuracy of the predictions. While progress has been made in filtering out eliminated contestants from the prediction process, further testing and evaluation are necessary to ensure the logic is robust and reliable.\n",
    "\n",
    "Another important aspect that requires attention is the handling of missing or incomplete data. Devising effective strategies to address missing values and ensuring the completeness of the dataset will contribute to more accurate predictions.\n",
    "\n",
    "Ongoing development and iterative improvements are crucial to align the simulation model more closely with the actual progression of the Survivor TV show. Through these efforts, meaningful insights can be provided, enabling better predictions of the order of elimination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b1d9c74",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "1. Robust Testing: You aim to set up more comprehensive testing to verify that the simulation is working as intended. This will involve designing test cases that cover various scenarios and edge cases to ensure the code handles them correctly. By systematically testing different input scenarios, you can gain confidence in the accuracy and reliability of the simulation.\n",
    "\n",
    "2. Updating x_test DataFrame: You plan to update the x_test DataFrame with data from previous events of the current season. This step involves formatting the CSV file to include the necessary additional data. You need to determine the appropriate format and structure of the CSV file to incorporate this information. Consider organizing the data in a way that allows easy merging or concatenation with the existing DataFrame to enrich the features used for prediction.\n",
    "\n",
    "3. Presentable Testing Results: You want to organize the testing results in a presentable format, including a learning curve, confidence intervals between different models tested, and other useful conclusions. This will involve analyzing the performance metrics obtained from the testing process, such as accuracy, and presenting them in a visually appealing manner. Additionally, you can explore techniques such as learning curves, which illustrate the model's performance as the amount of training data increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8777bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "61\n",
      "----------\n",
      "1\n",
      "24\n",
      "Model Accuracy: 12.5%\n",
      "----------\n",
      "----------\n",
      "2\n",
      "24\n",
      "Model Accuracy: 12.5%\n",
      "----------\n",
      "----------\n",
      "3\n",
      "25\n",
      "Model Accuracy: 12.0%\n",
      "----------\n",
      "----------\n",
      "4\n",
      "25\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "5\n",
      "24\n",
      "Model Accuracy: 8.333333333333332%\n",
      "----------\n",
      "----------\n",
      "6\n",
      "26\n",
      "Model Accuracy: 7.6923076923076925%\n",
      "----------\n",
      "----------\n",
      "7\n",
      "28\n",
      "Model Accuracy: 7.142857142857142%\n",
      "----------\n",
      "----------\n",
      "8\n",
      "25\n",
      "Model Accuracy: 16.0%\n",
      "----------\n",
      "----------\n",
      "9\n",
      "19\n",
      "Model Accuracy: 26.31578947368421%\n",
      "----------\n",
      "----------\n",
      "10\n",
      "16\n",
      "Model Accuracy: 6.25%\n",
      "----------\n",
      "----------\n",
      "11\n",
      "16\n",
      "Model Accuracy: 6.25%\n",
      "----------\n",
      "----------\n",
      "12\n",
      "18\n",
      "Model Accuracy: 5.555555555555555%\n",
      "----------\n",
      "----------\n",
      "13\n",
      "19\n",
      "Model Accuracy: 10.526315789473683%\n",
      "----------\n",
      "----------\n",
      "14\n",
      "20\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "15\n",
      "18\n",
      "Model Accuracy: 33.33333333333333%\n",
      "----------\n",
      "----------\n",
      "16\n",
      "21\n",
      "Model Accuracy: 23.809523809523807%\n",
      "----------\n",
      "----------\n",
      "17\n",
      "20\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "18\n",
      "20\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "19\n",
      "16\n",
      "Model Accuracy: 43.75%\n",
      "----------\n",
      "----------\n",
      "20\n",
      "16\n",
      "Model Accuracy: 12.5%\n",
      "----------\n",
      "----------\n",
      "21\n",
      "16\n",
      "Model Accuracy: 6.25%\n",
      "----------\n",
      "----------\n",
      "22\n",
      "16\n",
      "Model Accuracy: 12.5%\n",
      "----------\n",
      "----------\n",
      "23\n",
      "16\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "24\n",
      "16\n",
      "Model Accuracy: 43.75%\n",
      "----------\n",
      "----------\n",
      "25\n",
      "18\n",
      "Model Accuracy: 22.22222222222222%\n",
      "----------\n",
      "----------\n",
      "26\n",
      "18\n",
      "Model Accuracy: 22.22222222222222%\n",
      "----------\n",
      "----------\n",
      "27\n",
      "18\n",
      "Model Accuracy: 16.666666666666664%\n",
      "----------\n",
      "----------\n",
      "28\n",
      "20\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "29\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "30\n",
      "16\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "31\n",
      "20\n",
      "Model Accuracy: 30.0%\n",
      "----------\n",
      "----------\n",
      "32\n",
      "19\n",
      "Model Accuracy: 15.789473684210526%\n",
      "----------\n",
      "----------\n",
      "33\n",
      "16\n",
      "Model Accuracy: 31.25%\n",
      "----------\n",
      "----------\n",
      "34\n",
      "20\n",
      "Model Accuracy: 15.0%\n",
      "----------\n",
      "----------\n",
      "35\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "36\n",
      "16\n",
      "Model Accuracy: 25.0%\n",
      "----------\n",
      "----------\n",
      "37\n",
      "20\n",
      "Model Accuracy: 15.0%\n",
      "----------\n",
      "----------\n",
      "38\n",
      "20\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "39\n",
      "20\n",
      "Model Accuracy: 30.0%\n",
      "----------\n",
      "----------\n",
      "40\n",
      "20\n",
      "Model Accuracy: 10.0%\n",
      "----------\n",
      "----------\n",
      "41\n",
      "20\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "42\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "43\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "44\n",
      "20\n",
      "Model Accuracy: 10.0%\n",
      "----------\n",
      "----------\n",
      "45\n",
      "23\n",
      "Model Accuracy: 17.391304347826086%\n",
      "----------\n",
      "----------\n",
      "46\n",
      "18\n",
      "Model Accuracy: 27.77777777777778%\n",
      "----------\n",
      "----------\n",
      "47\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "48\n",
      "18\n",
      "Model Accuracy: 16.666666666666664%\n",
      "----------\n",
      "----------\n",
      "49\n",
      "20\n",
      "Model Accuracy: 15.0%\n",
      "----------\n",
      "----------\n",
      "50\n",
      "18\n",
      "Model Accuracy: 27.77777777777778%\n",
      "----------\n",
      "----------\n",
      "51\n",
      "20\n",
      "Model Accuracy: 15.0%\n",
      "----------\n",
      "----------\n",
      "52\n",
      "20\n",
      "Model Accuracy: 5.0%\n",
      "----------\n",
      "----------\n",
      "53\n",
      "18\n",
      "Model Accuracy: 16.666666666666664%\n",
      "----------\n",
      "----------\n",
      "54\n",
      "20\n",
      "Model Accuracy: 30.0%\n",
      "----------\n",
      "----------\n",
      "55\n",
      "20\n",
      "Model Accuracy: 10.0%\n",
      "----------\n",
      "----------\n",
      "56\n",
      "20\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "57\n",
      "20\n",
      "Model Accuracy: 20.0%\n",
      "----------\n",
      "----------\n",
      "58\n",
      "22\n",
      "Model Accuracy: 9.090909090909092%\n",
      "----------\n",
      "----------\n",
      "59\n",
      "18\n",
      "Model Accuracy: 11.11111111111111%\n",
      "----------\n",
      "----------\n",
      "60\n",
      "18\n",
      "Model Accuracy: 16.666666666666664%\n",
      "----------\n",
      "----------\n",
      "61\n",
      "18\n",
      "Model Accuracy: 16.666666666666664%\n",
      "----------\n",
      "Empty DataFrame\n",
      "Columns: [age, genderNumber]\n",
      "Index: []\n",
      "      orderOut\n",
      "1168         1\n",
      "1169         2\n",
      "1170         3\n",
      "1171         4\n",
      "1172         5\n",
      "1173         6\n",
      "1174         7\n",
      "1175         8\n",
      "1176         9\n",
      "1177        10\n",
      "1178        11\n",
      "1179        12\n",
      "1180        13\n",
      "1181        14\n",
      "1182        15\n",
      "1183        16\n",
      "1184        17\n",
      "1185        18\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# Use a random forest model that tries to predict the order the remaining contestants will be eliminated from the show.\n",
    "#       Return the contestant remaining that has the lowest orderOut prediction\n",
    "#       An orderOut value of 1 means that person was the first eleminated and the hightest orderOut in that season is the winner\n",
    "#       x_train is the age and gender of contestants in the training set\n",
    "#       y_train is the orderOut for contestants in the training set\n",
    "#       current_order is the orderOut value that is being predicted\n",
    "def person_prediction(remaining_contestants, x_train_current, y_train_current, current_order):\n",
    "    # Train the random forest model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(x_train_current, y_train_current)\n",
    "    \n",
    "    # print(\"----------------\")\n",
    "    # print(len(remaining_contestants))\n",
    "    # print(\"----------------\")\n",
    "\n",
    "    # Predict the order for the remaining contestants\n",
    "    x_test_current = remaining_contestants[['age', 'genderNumber']]\n",
    "    predicted_order = model.predict(x_test_current)\n",
    "\n",
    "    # Find the contestants with the smallest predicted order\n",
    "    min_predicted_order = np.min(predicted_order)\n",
    "    contestants_with_min_order = np.where(predicted_order == min_predicted_order)[0]\n",
    "\n",
    "    # Randomly select one contestant from those with the smallest predicted order\n",
    "    person_predicted = np.random.choice(contestants_with_min_order)\n",
    "\n",
    "    return person_predicted\n",
    "\n",
    "# Split dataframe into a list of dataframes grouped by column name\n",
    "def split_dataframe(df, column_name):\n",
    "    groups = df.groupby(column_name)\n",
    "    result = [group for _, group in groups]\n",
    "    return result\n",
    "\n",
    "# Call split_dataframe on column name \"version_season\"\n",
    "season_split = split_dataframe(castawayAll, 'version_season')\n",
    "\n",
    "# Give each contestant which order they were eliminated from the show\n",
    "for df in season_split:\n",
    "    df['orderOut'] = range(1, len(df) + 1)\n",
    "\n",
    "# Perform leave one group out cross-validation on the remaining code\n",
    "\n",
    "# Perform leave-one-group-out cross-validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Create a list of group labels corresponding to each DataFrame in season_split\n",
    "group_labels = [i for i, _ in enumerate(season_split)]\n",
    "\n",
    "print(len(season_split))\n",
    "print(len(group_labels))\n",
    "\n",
    "for_total_number_of_loops = 0\n",
    "\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "\n",
    "    for_total_number_of_loops = for_total_number_of_loops + 1\n",
    "\n",
    "    x_train = pd.concat([season_split[i][['age', 'genderNumber']] for i in train_index])\n",
    "    y_train = pd.concat([season_split[i][['orderOut']] for i in train_index])\n",
    "\n",
    "    x_test = pd.concat([season_split[i][['age', 'genderNumber']] for i in test_index])\n",
    "    y_test = pd.concat([season_split[i][['orderOut']] for i in test_index])\n",
    "\n",
    "    number_of_contestants = len(x_test)\n",
    "    order_out = 1\n",
    "    correct_predictions = 0\n",
    "\n",
    "    while len(x_test) > 0:\n",
    "        age_eliminated = x_test.iloc[0]['age']\n",
    "        gender_number_eliminated = x_test.iloc[0]['genderNumber']\n",
    "        # Print the values for the person who was eliminated\n",
    "        #print(\"Person eliminated:\")\n",
    "        #print(f\"Age: {age_eliminated}, Gender Number: {gender_number_eliminated}, Order Out: {order_out}\")\n",
    "        \n",
    "        # Select a person\n",
    "        prediction_person_index = person_prediction(x_test, x_train, y_train, order_out)\n",
    "        # print(\"-------------------------------------\")\n",
    "        # print(x_test)\n",
    "        # print(f\"Person prediction position: {prediction_person_index}\")\n",
    "        # print(f\"Person prediction age: {x_test.iloc[prediction_person_index]['age']}\")\n",
    "        \n",
    "        # print(f\"Person eleminated position: {prediction_person_index}\")\n",
    "        # print(f\"Person eleminated age: {age_eliminated}\")\n",
    "        # print(\"-------------------------------------\")\n",
    "        # Check if the prediction is correct\n",
    "        if prediction_person_index == 0:\n",
    "            correct_predictions += 1\n",
    "            \n",
    "        #TODO:: Update x_train and y_train to include the person who is dropping out\n",
    "        \n",
    "        # Remove the first element of x_test\n",
    "        x_test = x_test.iloc[1:]\n",
    "        order_out = order_out + 1\n",
    "\n",
    "    # Calculate and print the accuracy of the model\n",
    "    print(\"----------\")\n",
    "    print(for_total_number_of_loops)\n",
    "    print(number_of_contestants)\n",
    "    accuracy = (correct_predictions / number_of_contestants) * 100\n",
    "    print(f\"Model Accuracy: {accuracy}%\")\n",
    "    print(\"----------\")\n",
    "    \n",
    "print(x_test)\n",
    "print(y_test)\n",
    "print(for_total_number_of_loops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd9d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predict which person in x_test will be removed next\n",
    "# y_pred = model.predict(x_test.iloc[[0]])\n",
    "# y_pred = model.predict(x_test)\n",
    "\n",
    "# # Save the predicted outcomes to the list\n",
    "# predicted_outcomes.extend(y_pred)\n",
    "\n",
    "# # Print the predicted outcomes\n",
    "# print(\"Predicted Outcomes:\")\n",
    "# print(predicted_outcomes) \n",
    "\n",
    "# # Print the true outcomes\n",
    "# print(\"True Outcomes:\")\n",
    "# print(y_test)\n",
    "\n",
    "# # Calculate the accuracy of the predicted outcomes\n",
    "# accuracy = accuracy_score(y_test, predicted_outcomes)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# # Iterate through each test set\n",
    "# for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "#     # Get the training and test sets for the current iteration\n",
    "#     train_set = [season_split[i] for i in train_index]\n",
    "#     test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "#     # Iterate through each test DataFrame\n",
    "#     for i, test_df in enumerate(test_set):\n",
    "#         x_train = pd.concat(train_set)[['age', 'genderNumber', 'occupation']]\n",
    "#         y_train = pd.concat(train_set)['orderOut']\n",
    "\n",
    "#         # Fit the SVM model on the training data\n",
    "#         model.fit(x_train, y_train)\n",
    "\n",
    "#         # Predict the orderOut values for the test set\n",
    "#         x_test = test_df[['age', 'genderNumber']]\n",
    "#         y_pred = model.predict(X_test)\n",
    "\n",
    "#         # Save the predicted outcomes to the list\n",
    "#         predicted_outcomes.extend(y_pred)\n",
    "\n",
    "#         # Save the true outcomes to the list\n",
    "#         true_outcomes.extend(test_df['orderOut'])\n",
    "\n",
    "#         # Remove the row with the lowest orderOut value from the possible choices\n",
    "#         min_orderOut = min(test_df['orderOut'])\n",
    "#         test_set[i] = test_df[test_df['orderOut'] > min_orderOut]\n",
    "\n",
    "# # Print the predicted outcomes\n",
    "# print(\"Predicted Outcomes:\")\n",
    "# print(predicted_outcomes)\n",
    "\n",
    "# # Calculate the accuracy of the predicted outcomes\n",
    "# accuracy = accuracy_score(true_outcomes, predicted_outcomes)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379e46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Outcomes:\n",
      "[3, 2, 9, 3, 3, 2, 9, 8, 9, 9, 8, 9, 8, 9, 2, 3, 8, 8, 9, 9, 8, 2, 3, 8, 8, 16, 1, 3, 8, 8, 16, 1, 3, 9, 9, 8, 9, 8, 9, 8, 8, 9, 8, 9, 2, 9, 8, 9, 16, 3, 16, 3, 8, 8, 2, 1, 16, 8, 1, 2, 16, 2, 9, 9, 16, 9, 16, 2, 8, 8, 16, 2, 3, 1, 8, 1, 1, 3, 3, 8, 1, 8, 8, 8, 3, 3, 9, 16, 9, 8, 16, 16, 1, 8, 9, 9, 9, 1, 3, 9, 8, 2, 9, 8, 2, 9, 3, 8, 8, 9, 9, 9, 3, 16, 1, 8, 9, 3, 8, 8, 2, 16, 8, 1, 3, 16, 9, 16, 9, 8, 2, 1, 9, 8, 16, 5, 8, 9, 2, 9, 9, 8, 2, 1, 1, 8, 9, 8, 3, 8, 1, 8, 9, 16, 1, 8, 8, 8, 16, 9, 9, 8, 9, 8, 9, 2, 8, 9, 2, 3, 9, 2, 9, 8, 1, 3, 1, 1, 16, 8, 2, 8, 9, 1, 8, 9, 16, 3, 9, 8, 16, 8, 16, 2, 8, 9, 8, 9, 3, 9, 8, 8, 8, 3, 8, 8, 8, 8, 9, 9, 16, 9, 8, 8, 3, 9, 3, 1, 9, 9, 3, 9, 2, 8, 9, 2, 3, 8, 9, 8, 8, 9, 9, 9, 8, 8, 8, 1, 9, 8, 9, 9, 8, 9, 3, 9, 8, 8, 16, 8, 16, 1, 2, 3, 9, 8, 16, 8, 16, 1, 8, 9, 16, 3, 9, 9, 8, 9, 1, 1, 9, 8, 16, 8, 8, 9, 8, 1, 8, 9, 16, 9, 9, 16, 1, 9, 6, 8, 9, 8, 1, 1, 9, 8, 9, 8, 1, 9, 8, 9, 2, 8, 16, 9, 9, 3, 9, 2, 9, 9, 3, 8, 9, 2, 9, 9, 8, 16, 8, 8, 1, 9, 8, 16, 1, 2, 16, 2, 3, 8, 2, 9, 1, 9, 9, 2, 9, 2, 9, 9, 8, 9, 9, 8, 1, 9, 2, 9, 9, 8, 9, 9, 1, 8, 9, 1, 1, 16, 9, 2, 8, 1, 1, 9, 9, 9, 9, 8, 9, 9, 1, 9, 9, 2, 2, 1, 2, 1, 9, 2, 2, 3, 9, 1, 16, 2, 3, 9, 3, 3, 8, 2, 9, 9, 2, 9, 8, 9, 8, 9, 2, 3, 8, 16, 1, 9, 1, 9, 8, 16, 16, 8, 8, 9, 8, 3, 8, 16, 9, 1, 1, 8, 3, 1, 9, 8, 9, 8, 9, 3, 8, 1, 3, 16, 1, 9, 3, 1, 9, 8, 9, 8, 9, 9, 2, 8, 9, 9, 3, 1, 8, 2, 16, 8, 9, 1, 8, 9, 8, 8, 9, 8, 3, 16, 1, 1, 3, 16, 9, 1, 9, 8, 1, 8, 3, 9, 1, 9, 8, 8, 3, 9, 9, 5, 8, 9, 1, 9, 8, 2, 9, 9, 16, 9, 16, 8, 8, 9, 8, 9, 1, 8, 1, 3, 8, 9, 3, 1, 9, 9, 2, 16, 1, 2, 2, 3, 16, 8, 9, 8, 9, 8, 9, 8, 9, 9, 1, 9, 16, 16, 16, 2, 2, 8, 5, 1, 1, 9, 9, 1, 2, 8, 9, 8, 3, 8, 16, 9, 9, 9, 2, 8, 9, 1, 2, 9, 8, 3, 3, 8, 8, 8, 9, 1, 9, 2, 9, 9, 9, 3, 9, 2, 1, 9, 8, 8, 1, 2, 8, 1, 9, 3, 9, 9, 8, 3, 8, 9, 2, 3, 8, 9, 3, 16, 8, 9, 2, 16, 2, 8, 9, 2, 1, 9, 8, 3, 8, 9, 8, 8, 9, 9, 8, 8, 1, 3, 8, 2, 9, 9, 2, 8, 9, 9, 9, 8, 9, 3, 9, 1, 9, 3, 8, 2, 16, 9, 8, 8, 16, 9, 9, 9, 8, 1, 8, 8, 9, 9, 8, 3, 16, 9, 3, 3, 1, 1, 2, 8, 9, 9, 9, 8, 9, 8, 2, 8, 8, 8, 1, 8, 8, 9, 8, 9, 9, 9, 9, 3, 8, 8, 9, 9, 8, 1, 3, 8, 8, 3, 1, 9, 8, 9, 9, 9, 8, 1, 16, 2, 8, 9, 9, 8, 3, 1, 9, 2, 8, 3, 2, 9, 8, 1, 9, 16, 8, 1, 9, 9, 9, 16, 8, 8, 8, 3, 1, 3, 9, 9, 9, 16, 8, 9, 8, 8, 8, 3, 16, 1, 16, 8, 2, 1, 9, 3, 3, 3, 8, 2, 2, 8, 3, 8, 8, 8, 9, 1, 3, 1, 9, 9, 9, 1, 9, 16, 1, 8, 8, 1, 9, 9, 9, 1, 3, 3, 8, 9, 8, 8, 8, 3, 16, 8, 2, 3, 1, 8, 8, 9, 9, 9, 16, 2, 8, 9, 2, 5, 3, 9, 9, 16, 8, 8, 1, 16, 9, 1, 5, 16, 9, 9, 9, 3, 8, 3, 8, 8, 8, 2, 8, 9, 8, 8, 3, 8, 8, 8, 8, 3, 3, 9, 3, 9, 8, 9, 1, 3, 1, 1, 8, 8, 9, 8, 9, 16, 8, 8, 3, 3, 9, 9, 8, 8, 9, 9, 1, 1, 9, 2, 8, 3, 8, 2, 9, 9, 3, 2, 8, 2, 9, 9, 1, 2, 9, 8, 9, 8, 1, 3, 2, 9, 3, 9, 9, 8, 3, 8, 5, 8, 5, 16, 16, 9, 2, 3, 9, 1, 9, 16, 8, 2, 16, 9, 8, 3, 2, 16, 16, 9, 9, 9, 9, 8, 3, 1, 8, 8, 2, 9, 1, 8, 16, 9, 1, 8, 9, 5, 2, 9, 3, 8, 9, 16, 1, 16, 16, 2, 2, 3, 8, 3, 9, 1, 3, 2, 8, 16, 9, 2, 1, 3, 8, 9, 1, 3, 9, 1, 8, 9, 8, 8, 16, 16, 9, 1, 16, 8, 9, 3, 8, 3, 8, 8, 2, 8, 3, 1, 2, 8, 8, 8, 9, 16, 2, 9, 5, 1, 9, 3, 3, 8, 9, 9, 8, 3, 9, 9, 9, 1, 3, 8, 16, 1, 9, 2, 8, 8, 1, 2, 3, 3, 3, 2, 1, 8, 9, 9, 8, 8, 8, 8, 9, 9, 9, 2, 8, 3, 9, 9, 1, 9, 8, 9, 8, 16, 2, 9, 9, 9, 8, 8, 8, 5, 8, 8, 9, 9, 1, 8, 16, 9, 16, 5, 16, 8, 8, 1, 1, 2, 16, 9, 9, 16, 8, 9, 9, 8, 8, 8, 3, 9, 1, 9, 9, 9, 2, 8, 9, 9, 8, 3, 2, 16, 3, 2, 8, 8, 9, 1, 9, 9, 16, 8, 9, 8, 3, 9, 9, 8, 16, 16, 5, 8, 2, 2, 3, 3, 8, 2, 9, 9, 2, 1, 1, 3, 16, 3, 2, 1, 3, 16, 9, 16, 8, 2, 3, 9, 1, 16, 2, 8, 2, 3, 3, 8, 16, 3, 9, 1, 8, 1, 16, 8, 1, 8, 16, 9, 1, 9, 9, 8, 3, 9, 1, 1, 8, 9, 8, 8, 3, 8, 9, 2, 9, 8, 9, 16, 3, 8, 8, 8, 1, 1, 16, 8, 9, 8, 16, 9, 8, 5, 16, 8, 9, 9, 8, 3]\n",
      "Accuracy: 0.05986509274873524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the predicted outcomes\n",
    "predicted_outcomes = []\n",
    "\n",
    "# Create a list to store the true outcomes\n",
    "true_outcomes = []\n",
    "\n",
    "# Create a list of group labels corresponding to each DataFrame in season_split\n",
    "group_labels = [i for i, _ in enumerate(season_split)]\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Initialize the SVM model for each iteration\n",
    "    model = LogisticRegression()\n",
    "\n",
    "# Iterate through each test set\n",
    "for train_index, test_index in logo.split(season_split, groups=group_labels):\n",
    "    # Get the training and test sets for the current iteration\n",
    "    train_set = [season_split[i] for i in train_index]\n",
    "    test_set = [season_split[i] for i in test_index]\n",
    "\n",
    "    # Iterate through each test DataFrame\n",
    "    for i, test_df in enumerate(test_set):\n",
    "        X_train = pd.concat(train_set)[['age', 'genderNumber']]\n",
    "        y_train = pd.concat(train_set)['orderOut']\n",
    "\n",
    "        # Fit the SVM model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the orderOut values for the test set\n",
    "        X_test = test_df[['age', 'genderNumber']]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save the predicted outcomes to the list\n",
    "        predicted_outcomes.extend(y_pred)\n",
    "\n",
    "        # Save the true outcomes to the list\n",
    "        true_outcomes.extend(test_df['orderOut'])\n",
    "\n",
    "        # Remove the row with the lowest orderOut value from the possible choices\n",
    "        min_orderOut = min(test_df['orderOut'])\n",
    "        test_set[i] = test_df[test_df['orderOut'] > min_orderOut]\n",
    "\n",
    "# Print the predicted outcomes\n",
    "print(\"Predicted Outcomes:\")\n",
    "print(predicted_outcomes)\n",
    "\n",
    "# Calculate the accuracy of the predicted outcomes\n",
    "accuracy = accuracy_score(true_outcomes, predicted_outcomes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
